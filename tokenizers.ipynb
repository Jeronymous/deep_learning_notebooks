{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔎🔢 Hands-On Tokenizers (in Deep Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "- [📖 Introduction](#intro)\n",
    "- [🛠️ Install common librairies](##install)\n",
    "- [👨‍💻 Helpers to inspect tokenizers](#helpers)\n",
    "- [👀 Inspect tokenizers](#start)\n",
    "  - [🔬📚 See vocabulary of (small) tokenizers](#vocabulary)\n",
    "  - [🔬🕹️ See how tokenizers do tokenize texts](#️examples)\n",
    "  - [🔬☪ Tokenization with Arabic (and code-switching)](#arabic)\n",
    "  - [🔬🤼 Challenge tokenizers](#challenge)\n",
    "  - [🧪🏆 Benchmark fertility](#benchmark)\n",
    "  - [🔢💬 Chat templates](#templates)\n",
    "  - [🔢✂️ Padding and Truncation](#padding)\n",
    "  - [🤖🧠 Train a new tokenizer](#training)\n",
    "  - [🤖👩🏻‍⚕️ Tokenizer Surgery](#surgery)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## 📖 Introduction -->\n",
    "<h2 id=\"intro\">📖 Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tokenizer maps `string` $\\rightleftharpoons$ `list of tokens`.\n",
    "* `encode`(\"string\") $\\mapsto$ [\"list\", \"of\", \"tokens\"]\n",
    "* `decode`([\"list\", \"of\", \"tokens\"]) $\\mapsto$ \"string\"\n",
    "\n",
    "In deep learning, a tokenizer is a <u>pre-processing</u> and/or <u>post-processing</u> brick for an artificial neural network that process and/or generates text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DeepLearning/NLP, a token is a unit of text (sequence of characters or bytes) that is often characterized by:\n",
    "* an <u>index in the vocabulary</u> of tokens,\n",
    "* a string representer (for interpretability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is used to interpret inputs and/or outputs of a neural network.\n",
    "<br> It is a positive integer in a limited range, that is often used to index vectorial embeddings (as input: lookup table / as output: index in vector of probabilities).\n",
    "<br> The *encoding* part is used when the neural net is fed with text data (ex: Language Models).\n",
    "<br> The *decoding* part is used when the neural net outputs text data (ex: Text Generation with LM, Automatic Speech Recognition, Image Caption Generation, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When extracted from a string, a token can also be characterized the <u>positions in the original string</u> (start & end). <br>\n",
    "This is needed for application like extractive question answering, where we have to track the position of the answer in the original text to extract it. <br>\n",
    "(Caution with multi-bytes characters: position in bytes is not the same as position in characters.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good tokenizer can compress a string into a small number of tokens,\n",
    "while keeping a reasonable vocabulary size (number of possible unique tokens). <br>\n",
    "A popular measure of this efficiency is the <u>fertility</u> of the tokenizer, defined as the average number of tokens per word:\n",
    "$$\\text{fertility} = \\frac{\\text{number of tokens}}{\\text{number of words}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem of having a vocabulary with a limited size (and hard to grow) is <u>out-of-vocabulary (OOV)</u>,\n",
    "which neither word- nor character-level tokenizers can solve:\n",
    "* Each natural language uses between 100k and 100M words, so it is impossible to have a vocabulary that covers all words.\n",
    "* Even at the character level there about 150k unicode characters!\n",
    "\n",
    "A solution to the OOV problem is to work at <u>byte-level</u> (unicode), not character-level. <br>\n",
    "In state-of-the-art models, tokens are often <u>sub-word tokens</u>, \n",
    "* either at byte-level (so a token can be a \"sub-character\"), \n",
    "* or at character-level with a byte-level fallback for unicode characters that are not in the vocabulary.\n",
    "\n",
    "The table below show several levels of tokenization and illustrates that a trade-off must be found between vocabulary size and tokens'sequence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different tokenizations of 'Tout à 1€':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Token-level</th>\n",
       "      <th>Max.Vocab.Size</th>\n",
       "      <th>OOV</th>\n",
       "      <th>Seq.Length</th>\n",
       "      <th>Example</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long sequences /</th>\n",
       "      <td>⬆️</td>\n",
       "      <td>Bit</td>\n",
       "      <td>2</td>\n",
       "      <td>🟢</td>\n",
       "      <td>🔴</td>\n",
       "      <td>0┃1┃0┃1┃0┃1┃0┃0┃0┃1┃1┃0┃1┃1┃1┃1┃0┃1┃1┃1┃0┃1┃0┃1┃0┃1┃1┃1┃0┃1┃0┃...</td>\n",
       "      <td>[78]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few possible values</th>\n",
       "      <td></td>\n",
       "      <td>UTF8 Byte</td>\n",
       "      <td>256</td>\n",
       "      <td>🟢</td>\n",
       "      <td>🟠</td>\n",
       "      <td>84 (T)┃111 (o)┃117 (u)┃116 (t)┃32 (▁)┃195 (�)┃160 (�)┃32 (▁)┃49 (1)┃226 (�)┃130 (�)┃172 (�)</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td>Unicode</td>\n",
       "      <td>155k+</td>\n",
       "      <td>🟡</td>\n",
       "      <td>🟡</td>\n",
       "      <td>T┃o┃u┃t┃ ┃à┃ ┃1┃€</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td>Sub-word</td>\n",
       "      <td>300k+</td>\n",
       "      <td>🟡</td>\n",
       "      <td>🟢</td>\n",
       "      <td>▁To┃ut┃▁à┃▁┃1┃€</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short sequences /</th>\n",
       "      <td></td>\n",
       "      <td>Word</td>\n",
       "      <td>1M+</td>\n",
       "      <td>🟠</td>\n",
       "      <td>🟢</td>\n",
       "      <td>▁Tout┃▁à┃▁1€</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many possible values</th>\n",
       "      <td>⬇️</td>\n",
       "      <td>Phrase</td>\n",
       "      <td>∞</td>\n",
       "      <td>🔴</td>\n",
       "      <td>🟢</td>\n",
       "      <td>▁Tout▁à┃▁1€</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Token-level Max.Vocab.Size OOV Seq.Length  \\\n",
       "long sequences /      ⬆️        Bit       2          🟢   🔴           \n",
       "few possible values       UTF8 Byte     256          🟢   🟠           \n",
       "                            Unicode   155k+          🟡   🟡           \n",
       "                           Sub-word   300k+          🟡   🟢           \n",
       "short sequences /              Word     1M+          🟠   🟢           \n",
       "many possible values  ⬇️     Phrase       ∞          🔴   🟢           \n",
       "\n",
       "                     Example                                                                                       \\\n",
       "long sequences /                                0┃1┃0┃1┃0┃1┃0┃0┃0┃1┃1┃0┃1┃1┃1┃1┃0┃1┃1┃1┃0┃1┃0┃1┃0┃1┃1┃1┃0┃1┃0┃...   \n",
       "few possible values   84 (T)┃111 (o)┃117 (u)┃116 (t)┃32 (▁)┃195 (�)┃160 (�)┃32 (▁)┃49 (1)┃226 (�)┃130 (�)┃172 (�)   \n",
       "                                                                                                T┃o┃u┃t┃ ┃à┃ ┃1┃€   \n",
       "                                                                                                  ▁To┃ut┃▁à┃▁┃1┃€   \n",
       "short sequences /                                                                                    ▁Tout┃▁à┃▁1€   \n",
       "many possible values                                                                                  ▁Tout▁à┃▁1€   \n",
       "\n",
       "                            \n",
       "long sequences /      [78]  \n",
       "few possible values   [12]  \n",
       "                       [9]  \n",
       "                       [6]  \n",
       "short sequences /      [3]  \n",
       "many possible values   [2]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"Tout à 1€\"\n",
    "\n",
    "def tokenization_level_tradeoff_table(input):\n",
    "\n",
    "    import pandas as pd\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    def display_tokenized(l):\n",
    "        out = \"┃\".join([str(t) for t in l])\n",
    "        if len(l) > 20:\n",
    "            try:\n",
    "                out = out[:out.index(\"┃\", 60)+1] + \"...\"\n",
    "            except: pass\n",
    "        return out\n",
    "\n",
    "    def flatten(l):\n",
    "        return [item for sublist in l for item in sublist]\n",
    "\n",
    "    def decode_utf8(byte):\n",
    "        try:\n",
    "            return bytes([byte]).decode('utf-8')\n",
    "        except:\n",
    "            return \"�\"\n",
    "        \n",
    "    columns = [\"Token-level\", \"Max.Vocab.Size\", \"OOV\", \"Seq.Length\", \"Example\", \" \"]\n",
    "    data = [\n",
    "        [\"Bit\",         2,      \"🟢\", \"🔴\", flatten([[int(bit) for bit in format(ord(char), '08b')] for char in input])     ],\n",
    "        [\"UTF8 Byte\",   256,    \"🟢\", \"🟠\", [f\"{idx} ({decode_utf8(idx).replace(' ','▁')})\" for idx in list(input.encode(\"utf-8\"))]          ],\n",
    "        [\"Unicode\",    \"155k+\", \"🟡\", \"🟡\", list(input)                                                                     ],\n",
    "        [\"Sub-word\",   \"300k+\", \"🟡\", \"🟢\", flatten([[\"▁\"]+list(word) if any(char.isdigit() for char in word) else [(\"▁\"if i == 0 else \"\")+word[i:i+2] for i in range(0, len(word), 2)] for word in input.split()]) ],\n",
    "        [\"Word\",       \"1M+\",   \"🟠\", \"🟢\", [\"▁\"+word for word in input.split()]                                            ],\n",
    "        [\"Phrase\",     \"∞\",     \"🔴\", \"🟢\", [\"▁\"+\"▁\".join(input.split()[:2])] + [\"▁\"+word for word in input.split()[2:]]   ],\n",
    "    ]\n",
    "\n",
    "    note_column = [\"long sequences /\", \"few possible values\"] + [\"\"] * (len(data) - 4) + [\"short sequences /\", \"many possible values\"]\n",
    "    note_column_2 = [\"⬆️\"] + [\"\"] * (len(data) - 2) + [\"⬇️\"]\n",
    "    last_column = [f\"[{len(t[-1])}]\" for t in data]\n",
    "\n",
    "    data = [\n",
    "        [note] + cols[:-1] + [display_tokenized(cols[-1]), last_col]\n",
    "        for note, cols, last_col in zip(note_column_2, data, last_column)\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        dict((col, [v[icol] for v in data]) for (icol, col) in enumerate([\"\"] + columns)),\n",
    "        index = note_column\n",
    "    )\n",
    "\n",
    "print(f\"Different tokenizations of '{input}':\")\n",
    "tokenization_level_tradeoff_table(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤓 Implementation of dummy a tokenizer (tokens=characters/words)\n",
    "The decomposition of a string into tokens can be illustrated in this small code, where tokens can be words/characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSplitter:\n",
    "\n",
    "    def split(self, text: str) -> list:\n",
    "        return list(text)\n",
    "\n",
    "    def join(self, tokens: list) -> str:\n",
    "        return \"\".join(tokens)\n",
    "\n",
    "class WordSplitter:\n",
    "\n",
    "    _SPACE = \"▁\"\n",
    "\n",
    "    def split(self, text: str) -> list:\n",
    "        words = text.split(\" \")\n",
    "        return ([words[0]] + [self._SPACE+w for w in words[1:]]) if words else []\n",
    "        \n",
    "    def join(self, tokens: list) -> str:\n",
    "        return \"\".join(tokens).replace(self._SPACE, \" \")\n",
    "\n",
    "input = \"Mais, mais… vas t'en là-bas !\"\n",
    "\n",
    "for tokenizer in [CharSplitter(), WordSplitter()]:\n",
    "\n",
    "    encoded = tokenizer.split(input)\n",
    "\n",
    "    # Round-trip test\n",
    "    encoded_decoded = tokenizer.join(encoded)\n",
    "    assert encoded_decoded == input\n",
    "    \n",
    "    print(f\"== {tokenizer.__class__.__name__} ==\\n➡️ {encoded}\\n➡️ {encoded_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was to show the string decomposition principle.\n",
    "\n",
    "In reality, tokenizers are more complex when they are used with a neural network model, because of the vocabulary that has a **fixed size**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "\n",
    "    _SOS = \"<start>\"\n",
    "    _EOS = \"<end>\"\n",
    "    _UNK = \"<unk>\"\n",
    "    vocabulary = [_UNK, _SOS, _EOS]\n",
    "   \n",
    "    def encode(self, text: str) -> list:\n",
    "        # Dec\n",
    "        tokens_str = self.split(text)\n",
    "        tokens_idx = [\n",
    "            self.vocabulary.index(t) if t in self.vocabulary\n",
    "            else self.vocabulary.index(self._UNK)\n",
    "            for t in tokens_str\n",
    "        ]\n",
    "        return tokens_idx\n",
    "        \n",
    "    def encode_str(self, text: str) -> list:\n",
    "        return [self.vocabulary[idx] for idx in self.encode(text)]\n",
    "\n",
    "class CharTokenizer(Tokenizer, CharSplitter):\n",
    "\n",
    "    def __init__(self, vocabulary: list = [chr(i) for i in range(128)]):\n",
    "        self.vocabulary += vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Mais, mais… vas t'en là-bas !\"\n",
    "\n",
    "tokenizer = CharTokenizer()\n",
    "encoded = tokenizer.encode(input)\n",
    "encoded_str = tokenizer.encode_str(input)\n",
    "encoded_decoded = tokenizer.join(encoded_str)\n",
    "print(f\"{input}\\n➡️ {encoded}\\n➡️ {encoded_str}\\n➡️ {encoded_decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"install\">🛠️ Install common librairies</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular python libraries for tokenizers are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most popular tokenizer libraries\n",
    "!pip install tokenizers>=0.20,<0.21 # last version is buggy\n",
    "!pip install tiktoken #==0.8.0\n",
    "!pip install sentencepiece #==0.2.0\n",
    "\n",
    "# Librairies for neural networks that include tokenizers (usually wrap other lower-level tokenization libraries)\n",
    "!pip install transformers #==4.46.3\n",
    "# !pip install nemo #==6.0.3\n",
    "!pip install git+https://github.com/linagora-labs/NeMo.git pytorch_lightning==2.4.0 lhotse==1.28.0\n",
    "#!python -m pip install git+https://github.com/linagora-labs/NeMo.git@{main}#egg=nemo_toolkit[asr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip index versions tiktoken 2> /dev/null\n",
    "!pip index versions tokenizers 2> /dev/null\n",
    "!pip index versions sentencepiece 2> /dev/null\n",
    "\n",
    "# !pip index versions transformers 2> /dev/null\n",
    "# !pip index versions nemo 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also useful for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## 👨‍💻 Helpers to inspect tokenizers -->\n",
    "<h2 id=\"helpers\">👨‍💻 Helpers to inspect tokenizers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of interesting tokenizers, identified either by their tiktoken name or [Hugging Face repository name](https://huggingface.co/docs/huggingface_hub/en/guides/repository):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_tokenizers = {\n",
    "    \n",
    "    # LLM - TikToken\n",
    "    \"GPT 3.5\":  \"gpt-3.5-turbo\",\n",
    "    \"GPT 4\":    \"gpt-4\",\n",
    "    \n",
    "    # LLM - Hugging Face / transformers (prefix with \"https://huggingface.co/\" to get the model card URL)\n",
    "    \"Lucie\":        \"OpenLLM-France/Lucie-7B\",   # -> https://huggingface.co/OpenLLM-France/Lucie-7B\n",
    "    \"Gemma\":        \"google/gemma-7b\",\n",
    "    \"Phi 2\":        \"microsoft/phi-2\",\n",
    "    \"Phi 3\":        \"microsoft/Phi-3-medium-4k-instruct\",\n",
    "    \"Qwen\":         \"Qwen/Qwen2.5-7B\",\n",
    "    \"Falcon\":       \"tiiuae/falcon-7b\",\n",
    "    \"Mistral\":      \"mistralai/Mistral-7B-Instruct-v0.3\", # \"mistralai/Mistral-7B-v0.1\",\n",
    "    \"Llama 2\":      \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"Llama 3\":      \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    \"Croissant\":    \"croissantllm/CroissantLLMBase\",\n",
    "    \"Bloom\":        \"bigscience/bloom-7b1\",\n",
    "    \"Olmo 2\":       \"allenai/OLMo-2-1124-7B-Instruct\",\n",
    "    \"C4\":           \"CohereForAI/c4ai-command-r-plus\",\n",
    "    \"Aya\":          \"CohereForAI/aya-expanse-8b\",\n",
    "    \"Jais\":         \"inceptionai/jais-adapted-7b-chat\",\n",
    "    \"EuroLLM\":      \"utter-project/EuroLLM-9B\",\n",
    "    \"Zephyr\":       \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "\n",
    "    # ASR - Hugging Face / transformers\n",
    "    \"Whisper\":      \"openai/whisper-large-v3\",\n",
    "    # ASR - Hugging Face / nemo\n",
    "    \"Parakeet\":     \"nvidia/parakeet-ctc-1.1b\", # same as \"nvidia/parakeet-rnnt-1.1b\",\n",
    "}\n",
    "custom_tokenizers = { # Custom file paths\n",
    "    \"🐦 Perruche\":     f\"{os.environ['HOME']}/projects/Parakeet/tokenizer_spe_bpe_v1024/tokenizer.model\",\n",
    "}\n",
    "\n",
    "for name, file_or_folder in custom_tokenizers.items():    \n",
    "    if not os.path.exists(file_or_folder):\n",
    "        print(\"WARNING: {name} is not available at {file_or_folder}\")\n",
    "        continue\n",
    "    my_tokenizers[name] = file_or_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** some models (like [Llama](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)) might require to fill some agreements form to have access to the model (with your Hugging Face account).<br>\n",
    "In case of problem, you should have an explicit message with the URL to visit (and fill the form) to get access to the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are defined some helpers to load and play with tokenizers:\n",
    "* Create tokenizer:\n",
    "    * `load_tokenizer`( `tokenizer_name` ): load a tokenizer from its name (either a Hugging Face repository name or a token name).\n",
    "    * `load_tokenizer_with_cache`( `tokenizer_name` ): same thing with a cache to avoid downloading the same tokenizer multiple times.\n",
    "* Inspect tokenizer vocabulary:\n",
    "    * `vocabulary_size`( `tokenizer_name` ): get the number of tokens in the vocabulary.\n",
    "    * `get_vocabulary`( `tokenizer_name` ): return the list of tokens.\n",
    "    * `sorted_vocabulary`( `tokenizer_name` ): return the tokens sorted by length and alphabetically, in a table **(for small tokenizers only)**.\n",
    "* Apply tokenizer:\n",
    "    * `encode_decode`( `tokenizer_name` , `text` ): encode and decode a text with a tokenizer, returning all the intermediate steps.\n",
    "    * `show_templates`( `tokenizer_name`［, `chat`］): show chat templates of tokenizer(s) (see dedicated section later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def conform_tokenizer_name(name):\n",
    "    global my_tokenizers\n",
    "    if name in my_tokenizers:\n",
    "        return my_tokenizers[name]\n",
    "    return name\n",
    "\n",
    "def load_tokenizer(name):\n",
    "    \"\"\"\n",
    "    Load a tokenizer by name.\n",
    "    \"\"\"\n",
    "    # Conform name\n",
    "    name = conform_tokenizer_name(name)\n",
    "\n",
    "    # Load with the right library\n",
    "    # - TikToken\n",
    "    if name.lower().startswith(\"gpt\"):\n",
    "        import tiktoken\n",
    "        return tiktoken.encoding_for_model(name.lower())\n",
    "    # - SentencePiece\n",
    "    elif name.endswith(\".model\"):\n",
    "        import sentencepiece as spm\n",
    "        return spm.SentencePieceProcessor(model_file=name)\n",
    "    # - NeMo\n",
    "    elif name.lower().startswith(\"nvidia\"):\n",
    "        import nemo.collections.asr as nemo_asr\n",
    "        import logging\n",
    "        logging.getLogger('nemo_logger').setLevel(logging.ERROR)\n",
    "        if \"ctc\" in name:\n",
    "            nemo_model_class = nemo_asr.models.EncDecCTCModelBPE\n",
    "        elif \"rnn\" in name:\n",
    "            nemo_model_class = nemo_asr.models.EncDecRNNTBPEModel\n",
    "        else:\n",
    "            raise NotImplementedError(f\"NeMo model '{name}' not supported\")\n",
    "        model = nemo_model_class.from_pretrained(name)\n",
    "        return model.tokenizer.tokenizer\n",
    "    # - Transformers\n",
    "    else:\n",
    "        import transformers\n",
    "        try:\n",
    "            return transformers.AutoTokenizer.from_pretrained(name, trust_remote_code=True)\n",
    "        except Exception as err:\n",
    "            # Report the name in case of error\n",
    "            raise RuntimeError(f\"Could not load tokenizer '{name}': {err}\") from err\n",
    "\n",
    "def load_tokenizer_with_cache(name):\n",
    "    \"\"\"\n",
    "    Load a tokenizer by name, with cache.\n",
    "    \"\"\"\n",
    "    global _loaded_tokenizers\n",
    "    if name not in _loaded_tokenizers:\n",
    "        _loaded_tokenizers[name] = load_tokenizer(name)\n",
    "    return _loaded_tokenizers[name] \n",
    "\n",
    "if \"_loaded_tokenizers\" not in globals(): _loaded_tokenizers = {}\n",
    "\n",
    "def get_token_representer(tokenizer, idx, if_negative=\"<BOS>\"):\n",
    "    \"\"\"\n",
    "    Get the token string corresponding to an index.\n",
    "    \"\"\"\n",
    "    if isinstance(tokenizer, str):\n",
    "        tokenizer = load_tokenizer_with_cache(tokenizer)\n",
    "    if idx < 0: return if_negative\n",
    "    \n",
    "    representer = \"\"\n",
    "    if \"id_to_token\" in dir(tokenizer):\n",
    "        representer = tokenizer.id_to_token(idx)\n",
    "    elif \"convert_ids_to_tokens\" in dir(tokenizer):\n",
    "        representer = tokenizer.convert_ids_to_tokens([idx])\n",
    "    try:\n",
    "        decoded = tokenizer.decode([idx], skip_special_tokens=False)\n",
    "    except Exception as err:\n",
    "        decoded = tokenizer.decode([idx])\n",
    "    while isinstance(representer, list):\n",
    "        assert len(representer) == 1\n",
    "        representer = representer[0]\n",
    "    while isinstance(decoded, list):\n",
    "        assert len(decoded) == 1\n",
    "        decoded = decoded[0]\n",
    "    representer = normalize_for_display(representer, is_token=True)\n",
    "    decoded = normalize_for_display(decoded, is_token=True)\n",
    "    if not decoded.startswith(\"▁\") and representer.startswith(\"▁\"):\n",
    "        decoded = \"▁\" + decoded\n",
    "    if not decoded.endswith(\"▁\") and representer.endswith(\"▁\"):\n",
    "        decoded += \"▁\"\n",
    "    return decoded    \n",
    "\n",
    "def encode_decode(tokenizer, text, add_special_tokens=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Round-trip testing:\n",
    "    Encode an input text into a list of tokens, and decode the tokens back to a string.\n",
    "    \"\"\"\n",
    "    if isinstance(tokenizer, str):\n",
    "        tokenizer = load_tokenizer_with_cache(tokenizer)\n",
    "\n",
    "    if \"encode_batch\" in dir(tokenizer):\n",
    "        # TikToken\n",
    "        tokens = tokenizer.encode_batch(\n",
    "            [text],\n",
    "            allowed_special=\"all\" if add_special_tokens else set(),\n",
    "            disallowed_special=(),\n",
    "            **kwargs\n",
    "        )[0]\n",
    "        if hasattr(tokens, \"ids\"):\n",
    "            tokens = tokens.ids\n",
    "        decoded = tokenizer.decode(tokens)\n",
    "    elif \"SentencePiece\" in type(tokenizer).__name__:\n",
    "        # SentencePiece\n",
    "        tokens = tokenizer.encode(text,\n",
    "            add_bos=add_special_tokens,\n",
    "            add_eos=add_special_tokens,\n",
    "            emit_unk_piece=add_special_tokens,\n",
    "            **kwargs\n",
    "        )\n",
    "        decoded = tokenizer.decode([t for t in tokens if t >= 0])\n",
    "        # tokens_strings = tokenizer.encode(text,\n",
    "        #     out_type=str,\n",
    "        #     emit_unk_piece=add_special_tokens,\n",
    "        # )\n",
    "    else:\n",
    "        # transformers / tokenizers\n",
    "        tokenizer.add_eos_token = bool(add_special_tokens)\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=add_special_tokens, **kwargs)\n",
    "        decoded = tokenizer.decode(tokens, skip_special_tokens=not add_special_tokens)\n",
    "    \n",
    "    # Normalize for display\n",
    "    tokens_strings = [get_token_representer(tokenizer, idx, \"<BOS>\" if i == 0 else \"<SOS>\") for i, idx in enumerate(tokens)]\n",
    "    # Note : get_token_representer is already calling the equivalent of normalize_for_display(tokens_strings, is_token=True)\n",
    "    tokens_strings = normalize_for_display(tokens_strings, is_token=True, is_normalized=True)\n",
    "    norm_decoded = normalize_for_display(decoded)\n",
    "\n",
    "    return tokens, tokens_strings, decoded, norm_decoded\n",
    "\n",
    "def vocabulary_size(tokenizer, to_string=False):\n",
    "    \"\"\"\n",
    "    Get the vocabulary size of a tokenizer.\n",
    "    \"\"\"\n",
    "    if isinstance(tokenizer, str):\n",
    "        tokenizer = load_tokenizer_with_cache(tokenizer)\n",
    "    \n",
    "    N = None\n",
    "    for attr_name in \"n_vocab\", \"vocab_size\", \"get_vocab_size\":\n",
    "        if attr_name in dir(tokenizer):\n",
    "            N = getattr(tokenizer, attr_name)\n",
    "            if not isinstance(N, int):\n",
    "                assert callable(N)\n",
    "                N = N()\n",
    "            break\n",
    "    if not N:\n",
    "        raise NotImplementedError(f\"Vocabulary not supported for tokenizer '{tokenizer}'\")\n",
    "    if to_string:\n",
    "        def format_thoushands(N):\n",
    "            import math\n",
    "            if N < 1100:\n",
    "                return str(N)\n",
    "            if N - 1000 * math.floor(N/1000) < 100:\n",
    "                return f\"{N//1000}k\"\n",
    "            return f\"{N/1000:.1f}k\"\n",
    "        N = format_thoushands(N)\n",
    "    return N\n",
    "\n",
    "def get_vocabulary(tokenizer):\n",
    "    \"\"\"\n",
    "    Get the vocabulary of a tokenizer.\n",
    "    \"\"\"\n",
    "    if isinstance(tokenizer, str):\n",
    "        tokenizer = load_tokenizer_with_cache(tokenizer)\n",
    "\n",
    "    N = vocabulary_size(tokenizer)\n",
    "    try:\n",
    "        tokens_str = [tokenizer.decode([t], skip_special_tokens=False) for t in range(N)]\n",
    "    except Exception as err:\n",
    "        tokens_str = [normalize_for_display(tokenizer.decode([t]), is_token=True) for t in range(N)]\n",
    "    if \"id_to_piece\" in dir(tokenizer):\n",
    "        tokens_str_check = [normalize_for_display(tokenizer.id_to_piece(t), is_token=True) for t in range(N)]\n",
    "        for i, (t1, t2) in enumerate(zip(tokens_str, tokens_str_check)):\n",
    "            if t1 != t2:\n",
    "                if not t1.startswith(\"▁\") and t2.startswith(\"▁\"):\n",
    "                    tokens_str[i] = \"▁\" + tokens_str[i]\n",
    "    \n",
    "    tokens_str = [normalize_for_display(tok, is_token=True) for tok in tokens_str]\n",
    "    return tokens_str\n",
    "\n",
    "def sorted_vocabulary(tokenizer):\n",
    "    vocab = get_vocabulary(tokenizer)\n",
    "    tokens_by_length = {}\n",
    "    for token in vocab:\n",
    "        nchars = len(token.lstrip(\"▁\"))\n",
    "        sow = token.startswith(\"▁\")\n",
    "        key = (nchars, sow)\n",
    "        if key not in tokens_by_length:\n",
    "            tokens_by_length[key] = []\n",
    "        tokens_by_length[key].append(token)\n",
    "\n",
    "    data = []\n",
    "    for (nchars, sow) in sorted(tokens_by_length):\n",
    "        tokens = sorted(tokens_by_length[(nchars, sow)])\n",
    "        data.append({\n",
    "            \"nchars\": nchars,\n",
    "            \"start\": \"▶\" if sow else \"#…\",\n",
    "            \"#tokens\": len(tokens),\n",
    "            \"tokens\": tokens # normalize_for_display(tokens, is_token=True),\n",
    "        })\n",
    "\n",
    "    data.append({\n",
    "        \"nchars\": \"TOTAL\",\n",
    "        \"start\": \"\",\n",
    "        \"#tokens\": sum(d[\"#tokens\"] for d in data),\n",
    "        \"tokens\": \"\",\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def show_templates(tokenizers=my_tokenizers, chat=None):\n",
    "    if isinstance(tokenizers, str):\n",
    "        tokenizers = [tokenizers]\n",
    "    exemple_chat = chat if chat else [\n",
    "        {\"role\": \"user\", \"content\": \"Hello robot\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hello human! How can I help?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Make me a coffee\"},\n",
    "    ]\n",
    "    empty_chat = [\n",
    "        {\"role\": \"user\", \"content\": \".\"},\n",
    "        {\"role\": \"assistant\", \"content\": \".\"},\n",
    "    ]\n",
    "    for tokenizer in tokenizers:\n",
    "        title = f\"👤 {tokenizer}:\"\n",
    "        print(\"\\n\" + title + \"\\n\" + \"-\"*(len(title)+2))\n",
    "        tokenizer = load_tokenizer_with_cache(tokenizer)\n",
    "        try:\n",
    "            templated_chat = tokenizer.apply_chat_template(exemple_chat, tokenize=False)\n",
    "        except Exception as err:\n",
    "            # Templated chat is not supported by all tokenizers\n",
    "            print(f\"❌ Error with {conform_tokenizer_name(tokenizer)}: {err}\")\n",
    "            continue\n",
    "        # Split into turns\n",
    "        print(templated_chat)\n",
    "        ignore_index, _, _, _ = encode_decode(tokenizer, \".\", add_special_tokens=False)\n",
    "        ignore_index = ignore_index[-1:]\n",
    "        encoded, tokens_str, _, _ = encode_decode(tokenizer, templated_chat, add_special_tokens=False)\n",
    "        encoded0, tokens_str0, _, _ = encode_decode(tokenizer, tokenizer.apply_chat_template(empty_chat, tokenize=False), add_special_tokens=False)\n",
    "        current = 0\n",
    "        special_tokens_str = [[]]\n",
    "        after_token_str = [[]]\n",
    "        tokens_str0 = tokens_str0.split(\"┃\")\n",
    "        tokens_str = tokens_str.split(\"┃\")\n",
    "        assert len(tokens_str0) == len(encoded0), f\"{len(tokens_str0)} ≠ {len(encoded0)}\"\n",
    "        for (tok_str, tok_idx) in zip(tokens_str0, encoded0):\n",
    "            if tok_idx in ignore_index:\n",
    "                continue\n",
    "            if current < len(encoded) and tok_idx != encoded[current] and tok_idx in encoded:\n",
    "                while current < len(encoded) and tok_idx != encoded[current]:\n",
    "                    after_token_str[-1].append(tokens_str[current])\n",
    "                    current += 1\n",
    "                if special_tokens_str[-1]:\n",
    "                    special_tokens_str.append([])\n",
    "                    after_token_str.append([])\n",
    "            special_tokens_str[-1].append(tok_str)\n",
    "            current += 1\n",
    "        for i, (special, after) in enumerate(zip(special_tokens_str, after_token_str)):\n",
    "            print(\n",
    "                \"💬\",\n",
    "                normalize_for_display(special, is_token=True),\n",
    "                \"┃《…》\" if after else \"\" #, f\"{normalize_for_display(after, is_token=False)}\"\n",
    "            )\n",
    "\n",
    "# Will be defined later\n",
    "if \"normalize_for_display\" not in globals():\n",
    "    def normalize_for_display(text, *kargs, **kwargs): return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are defined helpers to apply tokenizers to a text.\n",
    "* `test_tokenizers`(`text`, `tokenizers`)`: round-trip encode/decode test on a text, for each tokenizer (displayed in a table).\n",
    "* `test_tokenizers_batch`(`tests`, `tokenizers`)`: same thing on a list of texts (as a dictionary, with keys as a text name, describing what you want to test).\n",
    "* `benchmark_fertility`(`dataset_configts`)`: compute the fertility of a tokenizer on a dataset or a list of datasets (displayed in a bar chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import json, os, re\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "# Disable datasets progress bars\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()\n",
    "\n",
    "# Tune display of pandas DataFrames (tables)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.colheader_justify', 'left') # WTF ? this does not work\n",
    "# pd.set_option('display.show_index', False) # Is there an option to avoid printing the index column of DataFrame?\n",
    "\n",
    "def test_tokenizers(\n",
    "    text,\n",
    "    tokenizers=my_tokenizers,\n",
    "    display_vocabulary_size=True,\n",
    "    display_fertility=True,\n",
    "    display_round_trip_result=True,\n",
    "    **kwargs\n",
    "    ):\n",
    "    if isinstance(tokenizers, str):\n",
    "        tokenizers = [tokenizers]\n",
    "    # Build a table with the encoded and decoded text for each tokenizer\n",
    "    has_comments = False\n",
    "    all_data = []\n",
    "    for tokenizer in tokenizers:\n",
    "        tokens, tokens_str, decoded_raw, decoded = encode_decode(tokenizer, text, **kwargs)\n",
    "        data = {\n",
    "            \"tokenizer\": tokenizer,\n",
    "        }\n",
    "        if display_vocabulary_size:\n",
    "            data[\"size\"] = vocabulary_size(tokenizer, True)\n",
    "        if display_fertility:\n",
    "            num_words = len(text.split())\n",
    "            num_tokens = len(tokens)\n",
    "            if tokens_str.startswith(\"<BOS>\"):\n",
    "                num_tokens -= 1\n",
    "            if tokens_str.endswith(\"<EOS>\"):\n",
    "                num_tokens -= 1\n",
    "            data[\"#tokens\"] = num_tokens\n",
    "            data[\"fert.\"] = round(num_tokens / num_words, 1)\n",
    "        if display_round_trip_result:\n",
    "            # Remove all tags in brackets (like <BOS>, <EOS>, <UNK>, ...)\n",
    "            normalized_decoded = re.sub(r\"<[^>]*>\", \"\", decoded_raw).strip()\n",
    "            text_strip = text.strip()\n",
    "            round_trip_ok = (normalized_decoded == text_strip)\n",
    "            \n",
    "            # Spot difference in the round-trip test in case of failure\n",
    "            diff_string = \"\"\n",
    "            if not round_trip_ok:\n",
    "                start1 = 0\n",
    "                start2 = 0\n",
    "                while start1 < len(text_strip) and start2 < len(normalized_decoded) and text_strip[start1] == normalized_decoded[start2]:\n",
    "                    start1 += 1\n",
    "                    start2 += 1\n",
    "                end1 = len(text_strip)\n",
    "                end2 = len(normalized_decoded)\n",
    "                while end1 > start1 and end2 > start2 and text_strip[end1-1] == normalized_decoded[end2-1]:\n",
    "                    end1 -= 1\n",
    "                    end2 -= 1\n",
    "\n",
    "                orig = cut_long_string(normalize_for_display(text_strip[start1:end1], is_token=True), 10)\n",
    "                new = cut_long_string(normalize_for_display(normalized_decoded[start2:end2], is_token=True), 10)\n",
    "\n",
    "                if \"<UNK>\" in decoded:\n",
    "                    diff_string = \"OOV\"\n",
    "                elif not orig:\n",
    "                    diff_string = f\"«{new}» added (char {start2+1}/{len(normalized_decoded)})\"\n",
    "                elif not new:\n",
    "                    diff_string = f\"«{orig}» removed (char {start1+1}/{len(text_strip)})\"\n",
    "                else:\n",
    "                    diff_string += \"«\"\n",
    "                    diff_string += orig\n",
    "                    diff_string += \"» ≠ «\"\n",
    "                    diff_string += new\n",
    "                    diff_string += \"»\"\n",
    "            \n",
    "            # Look if there are weird mixed tokens\n",
    "            weird_tokens = \"\"\n",
    "            _descr_mix_punc = \"mix alpha/punct\"\n",
    "            _descr_mix_num = \"mix alpha/num\"\n",
    "            _descr_more_than_1_digits = \"digits\"\n",
    "            for t in tokens_str.split(\"┃\"):\n",
    "                t = t.replace(\"\\\\n\", \"\\n\").replace(\"\\\\t\", \"\\t\").replace(\"\\\\r\", \"\\r\") # grrr\n",
    "                # mix of alphanum and punctuation\n",
    "                if _descr_mix_punc not in weird_tokens and any(c.isalnum() for c in t) and any(c in \".,;:!?…\\n\\t\" for c in t):\n",
    "                    if weird_tokens: weird_tokens += \", \"\n",
    "                    weird_tokens += _descr_mix_punc\n",
    "                # mix of alpha and numeric\n",
    "                if _descr_mix_num not in weird_tokens and any(c.isalpha() for c in t) and any(c.isdigit() for c in t):\n",
    "                    if weird_tokens: weird_tokens += \", \"\n",
    "                    weird_tokens += _descr_mix_num\n",
    "                # more than one digit\n",
    "                if _descr_more_than_1_digits not in weird_tokens and sum(c.isdigit() for c in t) > 1:\n",
    "                    if weird_tokens: weird_tokens += \", \"\n",
    "                    weird_tokens += _descr_more_than_1_digits\n",
    "\n",
    "            is_ok = (round_trip_ok and not weird_tokens)\n",
    "            if not is_ok:\n",
    "                has_comments = True\n",
    "\n",
    "            data[\"round-trip\"] = \"✅\" if is_ok else (\"❌\" if not round_trip_ok else \"⚠️\")\n",
    "            data[\"comment\"] = diff_string if not round_trip_ok else weird_tokens\n",
    "        data[\"encoded tokens\"]= cut_long_string(tokens_str)\n",
    "        data[\"decoded text\"]= cut_long_string(decoded)\n",
    "        all_data.append(data)\n",
    "\n",
    "    all_data = pd.DataFrame(all_data)\n",
    "    if not has_comments:\n",
    "        all_data = all_data.drop(columns=[\"comment\"])\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def cut_long_string(\n",
    "    text,\n",
    "    max_len=100,\n",
    "    separator= \"・・・\" # \"《…》\" # \"«…»\"\n",
    "    ):\n",
    "    if len(text) > max_len:\n",
    "        return text[:max_len//2] + separator + text[-max_len//2:]\n",
    "    return text\n",
    "\n",
    "def test_tokenizers_batch(\n",
    "    tests,\n",
    "    tokenizers=my_tokenizers,\n",
    "    sort_by_tokenizer=False,\n",
    "    **kwargs\n",
    "    ):\n",
    "\n",
    "    combined_results = {\n",
    "        \"TEST\": [],\n",
    "        \"tokenizer\": [],\n",
    "        \"size\": [],\n",
    "        \"fert.\": [],\n",
    "        \"round-trip\": [],\n",
    "        \"comment\": [],\n",
    "        \"encoded tokens\": [],\n",
    "        \"decoded text\": [],\n",
    "    }\n",
    "    for name, text in tqdm.tqdm(tests.items(), desc=\"Testing tokenizers\", unit=\"test\") if (len(tokenizers) * len(tests) > 10) else tests.items():\n",
    "        df = test_tokenizers(text, tokenizers, **kwargs)\n",
    "        \n",
    "        # Sort by fertility, and by tokenizer size if fertilities are equal\n",
    "        df['tmp'] = df['size'].apply(lambda x: eval(x.replace('k', '*1000').replace(' ', '')))\n",
    "        df = df.sort_values(by=[\"fert.\", \"tmp\"], ascending=True)\n",
    "        df = df.drop(columns=['tmp'])\n",
    "\n",
    "        for k in combined_results:\n",
    "            if k == \"TEST\":\n",
    "                combined_results[k] += [name] * len(df)\n",
    "            elif k not in df:\n",
    "                if k in [\"comment\"]:\n",
    "                    combined_results[k] += [\"\"] * len(df)\n",
    "                else:\n",
    "                    raise ValueError(f\"Key '{k}' not found in the DataFrame\")\n",
    "            else:\n",
    "                combined_results[k] += list(df[k].values)\n",
    "\n",
    "    combined_results = pd.DataFrame(combined_results)\n",
    "\n",
    "    if sort_by_tokenizer:\n",
    "        combined_results = combined_results.sort_values(by=[\"tokenizer\"])\n",
    "\n",
    "    return combined_results\n",
    "\n",
    "# Cache benchmark results (that are long to compute)\n",
    "_file_to_cache_results = \"expes/tokenizers_fertilities.json\"\n",
    "def clear_cache():\n",
    "    global fertilities, _loaded_tokenizers\n",
    "    fertilities = {}\n",
    "    if _file_to_cache_results and os.path.exists(_file_to_cache_results):\n",
    "        with open(_file_to_cache_results, \"r\") as f:\n",
    "            fertilities = json.load(f)\n",
    "\n",
    "    _loaded_tokenizers = {}\n",
    "\n",
    "if \"fertilities\" not in globals():\n",
    "    clear_cache()\n",
    "\n",
    "def benchmark_fertility(\n",
    "    dataset_configs, # = [\n",
    "    #     (\"wikimedia/wikipedia\", \"20231101.\" + lan)\n",
    "    #     for lan in [\"en\", \"fr\", \"de\", \"es\", \"it\"]\n",
    "    # ]\n",
    "    tokenizers=my_tokenizers,\n",
    "    max_docs = 1000,\n",
    "    max_characters = 1e6,\n",
    "    do_not_recompute=True,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Measure the fertility of tokenizers on some dataset(s).\n",
    "\n",
    "    Args:\n",
    "    - tokenizers: list of tokenizers to test\n",
    "    - dataset_configs: list of configurations to test. Those are positional arguments for datasets.load_dataset().\n",
    "    - max_docs: number of documents to test\n",
    "    - do_not_recompute: if True, will not recompute fertilities if already computed\n",
    "    \"\"\"\n",
    "    global fertilities\n",
    "\n",
    "    config_names = [\"/\".join(config) for config in dataset_configs]\n",
    "\n",
    "    conformed_tokenizers = [conform_tokenizer_name(t) for t in tokenizers]\n",
    "\n",
    "    if isinstance(dataset_configs, str):\n",
    "        dataset_configs = [dataset_configs]\n",
    "\n",
    "    for i_config, (args, config) in enumerate(zip(dataset_configs, config_names)):\n",
    "        if isinstance(args, str):\n",
    "            args = (args,)\n",
    "        # Do not recompute what was already computed\n",
    "        if do_not_recompute and all(tokenizer in fertilities.get(config, {}) for tokenizer in conformed_tokenizers):\n",
    "            continue\n",
    "        already_computed_tokenizers = set(fertilities.get(config, {}))\n",
    "        num_missing = len(set(conformed_tokenizers) - set(already_computed_tokenizers)) if do_not_recompute \\\n",
    "            else len(conformed_tokenizers)\n",
    "        if num_missing == 0:\n",
    "            continue\n",
    "\n",
    "        # Load the dataset\n",
    "        dataset = datasets.load_dataset(*args, split=\"train\", streaming=True)\n",
    "        num_words = 0\n",
    "        num_tokens = {}\n",
    "        # Accumulate statistics\n",
    "        num_characters = 0\n",
    "        for i_doc, doc in enumerate(tqdm.tqdm(dataset, desc=f\"Testing {num_missing} tokenizers on {config}\", total=max_docs)):\n",
    "            if i_doc >= max_docs:\n",
    "                break\n",
    "            if num_characters >= max_characters:\n",
    "                break\n",
    "            text = doc[\"text\"]\n",
    "            num_characters += len(text)\n",
    "            num_words += len(text.split())\n",
    "            for tokenizer in tokenizers:\n",
    "                tokenizer_name = conform_tokenizer_name(tokenizer)\n",
    "                if do_not_recompute and tokenizer_name in already_computed_tokenizers:\n",
    "                    continue\n",
    "                tokens = encode_decode(tokenizer, text, add_special_tokens=False)[0]\n",
    "                assert isinstance(tokens, list) and (not tokens or isinstance(tokens[0], int)), f\"Unexpected tokens: {tokens}\"\n",
    "                num_tokens[tokenizer_name] = num_tokens.get(tokenizer_name, 0) + len(tokens)\n",
    "        fertilities[config] = fertilities.get(config, {})\n",
    "        for tokenizer_name in num_tokens:\n",
    "            fertilities[config][tokenizer_name] = num_tokens[tokenizer_name] / num_words\n",
    "        \n",
    "        # Sort keys alphabetically\n",
    "        for c in fertilities.keys():\n",
    "            fertilities[c] = dict(sorted(fertilities[c].items(), key=lambda item: item[0]))\n",
    "        fertilities = dict(sorted(fertilities.items(), key=lambda item: item[0]))\n",
    "        \n",
    "        # Save results on disk\n",
    "        if _file_to_cache_results:\n",
    "            tmp_file = _file_to_cache_results + \".tmp\"\n",
    "            if not os.path.isdir(os.path.dirname(_file_to_cache_results)):\n",
    "                os.makedirs(os.path.dirname(_file_to_cache_results))\n",
    "            with open(tmp_file, \"w\") as f:\n",
    "                json.dump(fertilities, f, indent=2)\n",
    "            os.replace(tmp_file, _file_to_cache_results)\n",
    "\n",
    "    # Plot\n",
    "    num_cols = 2\n",
    "    num_rows = (len(dataset_configs)+1)//num_cols\n",
    "    if len(dataset_configs) % 2 == 0:\n",
    "        num_rows += 1\n",
    "    colors = [plt.cm.rainbow(i / len(tokenizers)) for i in range(len(tokenizers))]\n",
    "\n",
    "    # Sort tokenizers by increasing fertility\n",
    "    tokenizers = sorted(\n",
    "        tokenizers,\n",
    "        key=lambda t: sum(fertilities[config][conform_tokenizer_name(t)] for config in config_names[:2])\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 6*num_rows))\n",
    "\n",
    "    # Print one plot per configuration\n",
    "    max_yaxis = 0\n",
    "    for i_config, (args, config) in enumerate(zip(dataset_configs, config_names)):\n",
    "        fert = fertilities[config]\n",
    "        plt.subplot(num_rows, num_cols, i_config+1)\n",
    "        for i, (t, color) in enumerate(zip(tokenizers, colors)):\n",
    "            plt.bar([i+1], [fert[conform_tokenizer_name(t)]], color=color)\n",
    "        if isinstance(args, str):\n",
    "            plt.title(args)\n",
    "        else:\n",
    "            plt.title(\", \".join(args))\n",
    "        plt.ylabel(\"Fertility (tokens per word)\")\n",
    "        plt.xticks([i+1 for i in range(len(tokenizers))])\n",
    "        (y_min, y_max) = plt.ylim()\n",
    "        max_yaxis = max(max_yaxis, y_max)\n",
    "    # Rescale all the same\n",
    "    for i_config in range(len(dataset_configs)):\n",
    "        plt.subplot(num_rows, num_cols, i_config+1)\n",
    "        plt.ylim(0, max_yaxis)\n",
    "    \n",
    "    # Custom legend\n",
    "    plt.subplot(num_rows, num_cols, len(dataset_configs)+1)\n",
    "    for i, (tokenizer, color) in enumerate(zip(tokenizers, colors)):\n",
    "        plt.bar([0], [0], color=color, label=f\"{i+1}. {tokenizer} ({vocabulary_size(tokenizer, True)})\")\n",
    "    plt.legend(fancybox=True, shadow=True, title=\"Tokenizers\", loc='center', fontsize=15, ncol=min(2, len(tokenizers)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helpers to display things nicely. <br>\n",
    "There is a special treatment for string including both Arabic and latin characters (so that characters are displayed in the right order).\n",
    "<br> *(**Note**: suprisingly, [`python-bidi`](https://pypi.org/project/python-bidi/) was not doing a great job for this notebook using* `from bidi.algorithm import get_display`*)*\n",
    "\n",
    "![figs/tokenizers_arabic_reading.png](figs/tokenizers_arabic_reading.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☪ Test: Fix of display for text with Arabic and code-switching ☪\n",
      "─────────────────────────────────────────────────────────────────\n",
      "🧐❌ Original string ((🇫🇷) «Bonjour Jean-Pierre, ça va ?» / (🇬🇧) «Hello Jean-Pierre, how are you ?»)\n",
      "مرحباً Jean-Pierre، كيف حالك؟\n",
      "     (not correctly displayed in Arabic with code-switching)\n",
      "\n",
      "🔬 Word decomposition (of original string)\n",
      "  1- ‏مرحباً\n",
      "  2- Jean-Pierre\n",
      "  3- ‏،\n",
      "  4- ‏كيف\n",
      "  5- ‏حالك\n",
      "  6- ‏؟\n",
      "\n",
      "🔬 Character decomposition (of original string):\n",
      "ً┃ا┃ب┃ح┃ر┃‏م┃e┃r┃r┃e┃i┃P┃-┃n┃a┃e┃J┃‎▁،┃‏┃‎▁ف┃ي┃ك┃‏┃‎▁؟┃ك┃ل┃ا┃ح┃‏\n",
      "\n",
      "😎✅ String for display\n",
      "‏، كيف حالك؟‎Jean-Pierre ‏مرحباً \n",
      "     (read Arabic chunks from right to left 👈🏽 / Latin characters & number from left to right 👉🏽)\n",
      "\n",
      "🔬 Character decomposition (of string for display):\n",
      "‎<RLM>،┃‏┃‎▁ف┃ي┃ك┃‏┃‎▁؟┃ك┃ل┃ا┃ح┃‏┃<RLM>┃▁┃e┃r┃r┃e┃i┃P┃-┃n┃a┃e┃J┃‎<LRM>ً┃ا┃ب┃ح┃ر┃م┃‏┃‎▁\n",
      "─────────────────────────────────────────────────────────────────\n",
      "🧐❌ Original string ((🇫🇷) «Jean-Pierre, ça va ?» / (🇬🇧) «Jean-Pierre, how are you ?»)\n",
      "Jean-Pierre، كيف حالك؟\n",
      "\n",
      "😎✅ String for display\n",
      "‏، كيف حالك؟‎Jean-Pierre\n",
      "─────────────────────────────────────────────────────────────────\n",
      "🧐❌ Original string ((🇫🇷) «Bonjour Jean-Pierre» / (🇬🇧) «Hello Jean-Pierre»)\n",
      "مرحباً Jean-Pierre\n",
      "\n",
      "😎✅ String for display\n",
      "‎Jean-Pierre ‏مرحباً \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Display</th>\n",
       "      <th>Display of tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مرحباً Jean-Pierre، كيف حالك؟</td>\n",
       "      <td>‏، كيف حالك؟‎Jean-Pierre ‏مرحباً</td>\n",
       "      <td>‏مرحباً┃‎Jean-Pierre؟┃حالك┃كيف┃،┃‏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jean-Pierre، كيف حالك؟</td>\n",
       "      <td>‏، كيف حالك؟‎Jean-Pierre</td>\n",
       "      <td>‎Jean-Pierre؟┃حالك┃كيف┃،┃‏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مرحباً Jean-Pierre</td>\n",
       "      <td>‎Jean-Pierre ‏مرحباً</td>\n",
       "      <td>‏مرحباً┃‎Jean-Pierre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original                       Display                             \\\n",
       "0  مرحباً Jean-Pierre، كيف حالك؟  ‏، كيف حالك؟‎Jean-Pierre ‏مرحباً    \n",
       "1         Jean-Pierre، كيف حالك؟           ‏، كيف حالك؟‎Jean-Pierre   \n",
       "2             مرحباً Jean-Pierre              ‎Jean-Pierre ‏مرحباً    \n",
       "\n",
       "  Display of tokens                    \n",
       "0  ‏مرحباً┃‎Jean-Pierre؟┃حالك┃كيف┃،┃‏  \n",
       "1          ‎Jean-Pierre؟┃حالك┃كيف┃،┃‏  \n",
       "2                ‏مرحباً┃‎Jean-Pierre  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Unicode characters for Right-to-Left Mark (RLM) and Left-to-Right Mark (LRM)\n",
    "_RLM = '\\u200F'\n",
    "_LRM = '\\u200E'\n",
    "\n",
    "def normalize_for_display(text, is_token=False, fix_arabic=True, is_normalized=False):\n",
    "    \"\"\"\n",
    "    Normalize token/text for display.\n",
    "    \"\"\"\n",
    "    if isinstance(text, list):\n",
    "        \n",
    "        if is_token:\n",
    "            token_list = [normalize_for_display(t, is_token=True, fix_arabic=False, is_normalized=is_normalized) for t in text]\n",
    "            # Add a separator between tokens\n",
    "            token_str = \"┃\".join(token_list)\n",
    "            if fix_arabic:\n",
    "                return fix_arabic_display(token_str, arabic_right_to_left=None)\n",
    "            return token_str\n",
    "        else:\n",
    "            # Map function on each element\n",
    "            return [normalize_for_display(t, is_token=False, fix_arabic=fix_arabic, is_normalized=is_normalized) for t in text]\n",
    "    \n",
    "    if not is_normalized:\n",
    "        # Escape line breaks and tabs\n",
    "        text = text \\\n",
    "            .replace(\"\\n\", \"\\\\n\") \\\n",
    "            .replace(\"\\t\", \"\\\\t\") \\\n",
    "            .replace(\"\\r\", \"\\\\r\") \\\n",
    "            .replace(\" \", \"⍽\") # non-break spaces\n",
    "        \n",
    "        if is_token:\n",
    "            # Standard representation of whitespace\n",
    "            text = text \\\n",
    "                .replace(\" \", \"▁\") \\\n",
    "                .replace(\"Ġ\", \"▁\")\n",
    "            \n",
    "            # Special characters\n",
    "            text = text \\\n",
    "                .replace(_RLM, \"<RLM>\") \\\n",
    "                .replace(_LRM, \"<LRM>\") \\\n",
    "\n",
    "        # For non-ASCII characters that are NOT encoded in UTF-8\n",
    "        # \"Ã©\" -> \"é\", ...\n",
    "        # It happens with the token \"representation strings\" for byte-level models like Bloom, Qwen, Falcon, Llama 2, Olmo 2, C4, Aya \n",
    "        # if tokens are not decoded (should be deprecated with correct implementation)\n",
    "        # if \"Ã\" in text or \"â\" in text:\n",
    "        #     import ftfy\n",
    "        #     text = ftfy.fix_text(text, normalization=\"NFC\")\n",
    "        \n",
    "        # Special tokens\n",
    "        for special_in, special_out in {\n",
    "            # Mistral, Llama 2\n",
    "            \"<s>\": \"<BOS>\", \"</s>\": \"<EOS>\",\n",
    "            # C4, Aya\n",
    "            \"<BOS_TOKEN>\": \"<BOS>\", \"<|END_OF_TURN_TOKEN|>\": \"<EOS>\",\n",
    "            # Llama 3\n",
    "            \"<|begin_of_text|>\": \"<BOS>\", \"<|end_of_text|>\": \"<EOS>\",\n",
    "            # Gemma\n",
    "            \"<bos>\": \"<BOS>\", \"<eos>\": \"<EOS>\",\n",
    "            # Whisper\n",
    "            \"<|startoftranscript|>\": \"<BOS>\", \"<|endoftext|>\": \"<EOS>\",\n",
    "            # Nemo\n",
    "            \"⁇\": \"<UNK>\", \"<PAD>\": \"<pad>\",\n",
    "            # misc. tags\n",
    "            \"<|\": \"<\", \"|>\": \">\",\n",
    "        }.items():\n",
    "            text = text.replace(special_in, special_out)\n",
    "    \n",
    "    if fix_arabic:\n",
    "        text = fix_arabic_display(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def fix_arabic_display(text,\n",
    "    reverse_chunk_orders=True,\n",
    "    add_extra_spaces=True,\n",
    "    arabic_right_to_left=True,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Format a string with Arabic and latin characters (code-switching) for a good display in the notebook.\n",
    "    \"\"\"\n",
    "    if isinstance(text, list):\n",
    "        return [fix_arabic_display(i, reverse_chunk_orders=reverse_chunk_orders, add_extra_spaces=add_extra_spaces) for i in text]\n",
    "\n",
    "    # from bidi import get_display # so disappointing\n",
    "    # return get_display(text)\n",
    "\n",
    "    # Ignore empty text\n",
    "    if not text: return \"\"\n",
    "\n",
    "    # Remove exising marks (we could Ignore already converted text)\n",
    "    if _RLM in text or _LRM in text:\n",
    "        text = text.replace(_RLM, \"\").replace(_LRM, \"\")\n",
    "        # print(\"WARNING: not processing\", text); return text\n",
    "\n",
    "    def is_arabic(char):\n",
    "        if char in \" \\n\\t\" or is_separator(char): return None\n",
    "        return (ord(char) in range(0x600, 0x6ff)) # or char in \"،؟؛\"\n",
    "\n",
    "    def is_separator(char):\n",
    "        return char in \"┃\"\n",
    "\n",
    "    def contains_arabic(text):\n",
    "        return any(is_arabic(c) for c in text)\n",
    "\n",
    "    def contains_latin(text):\n",
    "        return any(not is_arabic(c) and c.isalpha() for c in text)\n",
    "\n",
    "    # Convert only code-switching text\n",
    "    if not contains_arabic(text) or not contains_latin(text):\n",
    "        if contains_arabic(text):\n",
    "            text = _RLM + text\n",
    "        return text\n",
    "\n",
    "    \n",
    "    is_current_arabic = is_arabic(text[0])\n",
    "    if is_current_arabic is None:\n",
    "        i = 1\n",
    "        while i < len(text) and is_current_arabic is None:\n",
    "            is_current_arabic = is_arabic(text[i])\n",
    "            i += 1\n",
    "    chunks_by_language = [\n",
    "        _RLM if is_current_arabic else _LRM\n",
    "    ]\n",
    "    must_add_extra_space = False\n",
    "\n",
    "    for ic, c in enumerate(text):\n",
    "        was_previous_arabic = is_current_arabic\n",
    "        is_current_arabic = is_arabic(c)\n",
    "        if is_current_arabic is None:\n",
    "            is_current_arabic = was_previous_arabic\n",
    "\n",
    "        if is_current_arabic != was_previous_arabic:\n",
    "            if must_add_extra_space and add_extra_spaces:\n",
    "                chunks_by_language[-1] += \" \"\n",
    "            # Add direction switch mark before the character\n",
    "            chunks_by_language.append(_RLM if is_current_arabic else _LRM)\n",
    "            # Add an extra space before the code-switching\n",
    "            must_add_extra_space = (text[ic-1] == \" \")\n",
    "\n",
    "        chunks_by_language[-1] += c\n",
    "\n",
    "    if must_add_extra_space and add_extra_spaces:\n",
    "        chunks_by_language[-1] += \" \"\n",
    "\n",
    "    # Reverse the chunk order\n",
    "    if reverse_chunk_orders:\n",
    "\n",
    "        # Put separators on the other side (when they are affected to Arabic segments)\n",
    "        for i, chunk in enumerate(chunks_by_language):\n",
    "            assert chunk and chunk[0] in (_RLM + _LRM)\n",
    "            is_current_arabic = chunk[0] in _RLM\n",
    "\n",
    "            next_chunk = chunks_by_language[i+1] if i+1 < len(chunks_by_language) else chunk\n",
    "            is_next_arabic = next_chunk[0] in _RLM\n",
    "            ends_with_separator = is_separator(chunk[-1])\n",
    "\n",
    "            if ends_with_separator and (is_current_arabic != is_next_arabic) and not is_separator(next_chunk[1]):\n",
    "                # Move the separator that is supposed to be at the end/right of the Arabic chunk, on the left/end of the Latin chunk\n",
    "                # and same problem when there is an Arabic chunk after a Latin chunk (it will be on the left)\n",
    "                chunks_by_language[i] = chunk[:-1]\n",
    "                move_at_the_end = is_current_arabic if arabic_right_to_left is not False else not is_current_arabic\n",
    "                if move_at_the_end:\n",
    "                    chunks_by_language[i+1] = next_chunk[0] + next_chunk[1:] + chunk[-1]\n",
    "                else:\n",
    "                    chunks_by_language[i+1] = next_chunk[0] + chunk[-1] + next_chunk[1:]\n",
    "\n",
    "        if arabic_right_to_left:\n",
    "            chunks_by_language = chunks_by_language[::-1]\n",
    "        elif arabic_right_to_left is None:\n",
    "            # Special treatment for tokens\n",
    "            for i, chunk in enumerate(chunks_by_language):\n",
    "                if contains_arabic(text) and \"┃\" in text:\n",
    "                    chunks_by_language[i] = \"┃\".join(chunk.split(\"┃\")[::-1])\n",
    "\n",
    "    return \"\".join(chunks_by_language)\n",
    "\n",
    "def add_rlm_and_lrm_arabic(text):\n",
    "    \"\"\"\n",
    "    Add Right-to-Left and Left-to-Right marks to Arabic text.\n",
    "    \"\"\"\n",
    "    return fix_arabic_display(\n",
    "        text.replace(_RLM, \"\").replace(_LRM, \"\"),\n",
    "        reverse_chunk_orders=False,\n",
    "        add_extra_spaces=False,\n",
    "        arabic_right_to_left=False,\n",
    "    )\n",
    "\n",
    "# --- Tests ---\n",
    "\n",
    "def test_arabic_codeswitching_display(inputs, comments=None):\n",
    "    title = \"☪ Test: Fix of display for text with Arabic and code-switching ☪\"\n",
    "    separator = \"─\"*(len(title)+1)\n",
    "    print(f\"{title}\\n\" + separator)\n",
    "\n",
    "    if not comments:\n",
    "        comments = []\n",
    "    if len(comments) < len(inputs):\n",
    "        comments += [\"\"] * (len(inputs) - len(comments))\n",
    "    inputs_for_display = [fix_arabic_display(i) for i in inputs]\n",
    "    list_words = []\n",
    "\n",
    "    for i, (input, comment, display_input) in enumerate(zip(inputs, comments, inputs_for_display)):\n",
    "\n",
    "        words = input.split()\n",
    "        new_words = []\n",
    "        for w in words:\n",
    "            w2 = [wi for wi in re.split(r\"([،؟])\", w) if wi]\n",
    "            new_words.extend(w2)\n",
    "        words = new_words\n",
    "        list_words.append(words)\n",
    "\n",
    "        print_details = (i == 0)\n",
    "\n",
    "        if i > 0: print(separator)\n",
    "        print(\"🧐❌ Original string\" + (f\" ({comment})\" if comment else \"\"))\n",
    "        print(input)\n",
    "        if print_details:\n",
    "            print(\" \" * 5 + \"(not correctly displayed in Arabic with code-switching)\")\n",
    "\n",
    "        def show_character_decomposition(text, desc):\n",
    "            print(f\"\\n🔬 Character decomposition (of {desc}):\")\n",
    "            print(normalize_for_display(list(text), is_token=True))\n",
    "            # # Uncomment for debugging (see all characters encoded, one by line)\n",
    "            # for i, c in enumerate(text):\n",
    "            #     c = c.replace(_RLM, \"<RLM>\").replace(_LRM, \"<LRM>\")\n",
    "            #     print(f\" {i+1:2d}- {c}\")\n",
    "\n",
    "        if print_details:\n",
    "            print(\"\\n🔬 Word decomposition (of original string)\")\n",
    "            for iw, word in enumerate(words):\n",
    "                print(f\" {iw+1:2d}- {fix_arabic_display(word)}\")\n",
    "\n",
    "            show_character_decomposition(input, \"original string\")\n",
    "\n",
    "        print(\"\\n😎✅ String for display\")\n",
    "        print(display_input)\n",
    "        if print_details:\n",
    "            print(\" \" * 5 + \"(read Arabic chunks from right to left 👈🏽 / Latin characters & number from left to right 👉🏽)\")\n",
    "\n",
    "        if print_details:\n",
    "            for text, desc in [\n",
    "                (display_input, \"string for display\"),\n",
    "                # (normalize_for_display(words, is_token=True), \"tokens for display\")\n",
    "            ]:\n",
    "                show_character_decomposition(text, desc)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Original\": inputs,\n",
    "        \"Display\": inputs_for_display,\n",
    "        \"Display of tokens\": [normalize_for_display(words, is_token=True) for words in list_words],\n",
    "    })\n",
    "\n",
    "test_arabic_codeswitching_display(\n",
    "    (\n",
    "        \"مرحباً Jean-Pierre، كيف حالك؟\",\n",
    "        \"Jean-Pierre، كيف حالك؟\",\n",
    "        \"مرحباً Jean-Pierre\",\n",
    "    ), (\n",
    "        \"(🇫🇷) «Bonjour Jean-Pierre, ça va ?» / (🇬🇧) «Hello Jean-Pierre, how are you ?»\",\n",
    "        \"(🇫🇷) «Jean-Pierre, ça va ?» / (🇬🇧) «Jean-Pierre, how are you ?»\",\n",
    "        \"(🇫🇷) «Bonjour Jean-Pierre» / (🇬🇧) «Hello Jean-Pierre»\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the tokenizer download / loading (which can be long 🥱):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    }
   ],
   "source": [
    "for tokenizer in my_tokenizers:\n",
    "    load_tokenizer_with_cache(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test encoding and decoding with a simple string with a tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in encode_decode(\n",
    "    \"Llama 3\", # tokenizer\n",
    "    \"Bonjour à tous !\" # input\n",
    "    ):\n",
    "    print(\"➡️\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"start\">👀 Inspect tokenizers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"vocabulary\">🔬📚 See vocabulary of (small) tokenizers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>nchars</th>\n",
       "      <th>start</th>\n",
       "      <th>#tokens</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#…</td>\n",
       "      <td>27</td>\n",
       "      <td>[', a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>▶</td>\n",
       "      <td>25</td>\n",
       "      <td>[▁', ▁a, ▁b, ▁c, ▁d, ▁e, ▁f, ▁g, ▁h, ▁i, ▁j, ▁k, ▁l, ▁m, ▁n, ▁o, ▁p, ▁r, ▁s, ▁t, ▁u, ▁v, ▁w, ▁y, ▁z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>#…</td>\n",
       "      <td>119</td>\n",
       "      <td>[ab, ac, ad, ag, ah, ak, al, am, an, ap, ar, as, at, av, ay, be, ce, ch, ci, ck, co, ct, cy, de, du, ed, ef, el, em, en, ep, er, es, et, ew, fe, ff, ft, ge, gg, gn, ht, ia, ib, ic, id, ie, if, ig, il, im, in, ip, ir, is, it, iv, ix, iz, ke, ks, ld, le, li, ll, ly, me, mo, na, nd, ne, nt, od, og, ol, om, on, oo, op, or, os, ot, ou, ow, oy, pe, ph, pl, pp, ps, pt, qu, ra, re, ri, ro, ru, ry, se, so, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>▶</td>\n",
       "      <td>114</td>\n",
       "      <td>[▁ab, ▁ac, ▁ad, ▁af, ▁ag, ▁ah, ▁al, ▁am, ▁an, ▁ap, ▁ar, ▁as, ▁at, ▁be, ▁bl, ▁bo, ▁br, ▁bu, ▁by, ▁ca, ▁ch, ▁cl, ▁co, ▁cr, ▁de, ▁do, ▁dr, ▁ed, ▁el, ▁em, ▁en, ▁es, ▁eu, ▁ev, ▁ex, ▁fa, ▁fe, ▁fl, ▁fo, ▁fr, ▁gl, ▁go, ▁gr, ▁gu, ▁ha, ▁he, ▁ho, ▁hu, ▁if, ▁im, ▁in, ▁is, ▁it, ▁jo, ▁ke, ▁kn, ▁la, ▁le, ▁li, ▁lo, ▁ma, ▁me, ▁mo, ▁mr, ▁mu, ▁my, ▁ne, ▁no, ▁ob, ▁of, ▁oh, ▁ok, ▁on, ▁op, ▁or, ▁pa, ▁pe, ▁ph, ▁pl, ▁po, ▁pr, ▁qu, ▁ra, ▁re, ▁ro, ▁sa, ▁sc, ▁se, ▁sh, ▁sk, ▁sl, ▁sm, ▁so, ▁sp, ▁st, ▁su, ▁sy, ▁ta, ▁te, ▁th, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>#…</td>\n",
       "      <td>151</td>\n",
       "      <td>[ace, ach, ack, act, ade, ady, age, ail, aim, ain, all, als, ame, and, ang, ank, ans, ant, ard, are, ark, ars, art, ary, ase, ash, ass, ast, ate, ath, ave, ber, ble, ced, ces, con, cri, cus, day, der, ead, ect, ell, ens, ent, ere, erm, ers, ert, ess, est, ets, ety, ful, ger, her, hip, ial, ian, ice, ich, ick, ics, ict, ide, ied, ies, iew, iff, igh, ign, ild, ile, ill, ily, ind, ine, ing, ink, int, ion, ire, ise, ish, iss, ist, ite, ith, its, itt, ity, ive, ize, kes, led, les, lic, lud, nce, nds, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>▶</td>\n",
       "      <td>174</td>\n",
       "      <td>[▁acc, ▁act, ▁add, ▁adv, ▁all, ▁and, ▁any, ▁app, ▁are, ▁arg, ▁art, ▁ask, ▁ass, ▁att, ▁aut, ▁bas, ▁bec, ▁beg, ▁beh, ▁bel, ▁bet, ▁big, ▁bit, ▁bra, ▁bre, ▁bus, ▁but, ▁can, ▁car, ▁che, ▁cle, ▁col, ▁com, ▁con, ▁cor, ▁cou, ▁cre, ▁cur, ▁day, ▁dec, ▁def, ▁des, ▁det, ▁did, ▁dis, ▁don, ▁ear, ▁eas, ▁eff, ▁ele, ▁end, ▁eng, ▁ent, ▁exp, ▁ext, ▁fam, ▁far, ▁few, ▁fin, ▁fir, ▁for, ▁fun, ▁gen, ▁get, ▁god, ▁got, ▁gra, ▁had, ▁has, ▁hel, ▁her, ▁him, ▁his, ▁hon, ▁how, ▁hum, ▁ide, ▁imp, ▁inc, ▁ind, ▁inf, ▁ins, ▁int, ▁inv, ▁iss, ▁its, ▁jud, ▁lar, ▁law, ▁leg, ▁let, ▁loc, ▁lot, ▁man, ▁mar, ▁may, ▁med, ▁mem, ▁met, ▁min, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>#…</td>\n",
       "      <td>75</td>\n",
       "      <td>[able, ably, aint, ally, alth, ance, ange, arch, ason, atch, ated, ater, ates, ause, blem, body, cept, cess, cial, ence, ense, ents, enty, ered, eric, ever, fore, form, hing, ible, ical, ices, ient, ific, ight, ines, ings, ions, ious, ited, ject, king, llow, ment, nder, ness, ning, olog, oney, onna, osed, ough, ould, ound, ount, ouse, ower, pect, ract, reat, ress, ross, self, stem, ther, ting, ular, ures, vern, vers, very, ving, ward, ways, ween]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>▶</td>\n",
       "      <td>158</td>\n",
       "      <td>[▁able, ▁also, ▁appe, ▁away, ▁back, ▁been, ▁best, ▁book, ▁both, ▁call, ▁came, ▁care, ▁case, ▁cent, ▁char, ▁coll, ▁come, ▁comm, ▁comp, ▁conc, ▁conf, ▁cons, ▁cont, ▁cour, ▁didn, ▁diff, ▁dire, ▁dist, ▁does, ▁done, ▁down, ▁each, ▁even, ▁ever, ▁exam, ▁expl, ▁fact, ▁feel, ▁find, ▁five, ▁form, ▁four, ▁frie, ▁from, ▁full, ▁give, ▁good, ▁hand, ▁happ, ▁hard, ▁have, ▁head, ▁hear, ▁help, ▁here, ▁high, ▁home, ▁hund, ▁inst, ▁into, ▁just, ▁keep, ▁kind, ▁know, ▁last, ▁lead, ▁lear, ▁left, ▁life, ▁like, ▁list, ▁long, ▁look, ▁love, ▁made, ▁make, ▁many, ▁mark, ▁mean, ▁miss, ▁more, ▁most, ▁move, ▁much, ▁must, ▁name, ▁need, ▁next, ▁okay, ▁once, ▁only, ▁open, ▁over, ▁part, ▁pass, ▁peop, ▁pers, ▁plan, ▁play, ▁poss, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>#…</td>\n",
       "      <td>26</td>\n",
       "      <td>[ately, ather, ating, ation, ative, atter, ature, ction, erest, ether, ident, ility, iness, ision, ities, ition, ittle, ments, other, ought, ready, thing, ually, uring, ution, velop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>▶</td>\n",
       "      <td>70</td>\n",
       "      <td>[▁about, ▁after, ▁again, ▁allow, ▁being, ▁belie, ▁build, ▁child, ▁claim, ▁clear, ▁could, ▁count, ▁court, ▁creat, ▁doesn, ▁doing, ▁eight, ▁every, ▁exper, ▁first, ▁found, ▁gener, ▁going, ▁gonna, ▁great, ▁house, ▁inter, ▁light, ▁maybe, ▁means, ▁might, ▁money, ▁never, ▁order, ▁other, ▁place, ▁point, ▁power, ▁produ, ▁quest, ▁right, ▁small, ▁somet, ▁stand, ▁start, ▁state, ▁still, ▁thank, ▁their, ▁there, ▁these, ▁thing, ▁think, ▁those, ▁thous, ▁three, ▁today, ▁trans, ▁under, ▁using, ▁video, ▁watch, ▁water, ▁where, ▁which, ▁while, ▁whole, ▁world, ▁would, ▁years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>#…</td>\n",
       "      <td>5</td>\n",
       "      <td>[ations, ention, ertain, ically, idence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>▶</td>\n",
       "      <td>42</td>\n",
       "      <td>[▁&lt;UNK&gt;▁, ▁always, ▁americ, ▁around, ▁before, ▁better, ▁called, ▁change, ▁commun, ▁compan, ▁comple, ▁consid, ▁contin, ▁course, ▁enough, ▁experi, ▁family, ▁follow, ▁govern, ▁happen, ▁having, ▁import, ▁includ, ▁inform, ▁little, ▁making, ▁number, ▁partic, ▁people, ▁person, ▁pretty, ▁really, ▁reason, ▁record, ▁saying, ▁school, ▁second, ▁should, ▁system, ▁things, ▁though, ▁trying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>#…</td>\n",
       "      <td>1</td>\n",
       "      <td>[ational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>▶</td>\n",
       "      <td>21</td>\n",
       "      <td>[▁already, ▁another, ▁because, ▁believe, ▁between, ▁certain, ▁develop, ▁differe, ▁example, ▁getting, ▁hundred, ▁looking, ▁problem, ▁process, ▁support, ▁thought, ▁through, ▁underst, ▁whether, ▁without, ▁working]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>▶</td>\n",
       "      <td>8</td>\n",
       "      <td>[▁actually, ▁anything, ▁business, ▁interest, ▁probably, ▁question, ▁thousand, ▁together]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>▶</td>\n",
       "      <td>3</td>\n",
       "      <td>[▁different, ▁important, ▁something]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>▶</td>\n",
       "      <td>3</td>\n",
       "      <td>[▁everything, ▁government, ▁understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td></td>\n",
       "      <td>1024</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nchars start  #tokens  \\\n",
       "0       0   ▶       1      \n",
       "1       1  #…      27      \n",
       "2       1   ▶      25      \n",
       "3       2  #…     119      \n",
       "4       2   ▶     114      \n",
       "5       3  #…     151      \n",
       "6       3   ▶     174      \n",
       "7       4  #…      75      \n",
       "8       4   ▶     158      \n",
       "9       5  #…      26      \n",
       "10      5   ▶      70      \n",
       "11      6  #…       5      \n",
       "12      6   ▶      42      \n",
       "13      7  #…       1      \n",
       "14      7   ▶      21      \n",
       "15      8   ▶       8      \n",
       "16      9   ▶       3      \n",
       "17     10   ▶       3      \n",
       "18     11   ▶       1      \n",
       "19  TOTAL        1024      \n",
       "\n",
       "   tokens                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [▁]  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [', a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z]  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [▁', ▁a, ▁b, ▁c, ▁d, ▁e, ▁f, ▁g, ▁h, ▁i, ▁j, ▁k, ▁l, ▁m, ▁n, ▁o, ▁p, ▁r, ▁s, ▁t, ▁u, ▁v, ▁w, ▁y, ▁z]  \n",
       "3                                                                                                                                                                                                                                                                                                               [ab, ac, ad, ag, ah, ak, al, am, an, ap, ar, as, at, av, ay, be, ce, ch, ci, ck, co, ct, cy, de, du, ed, ef, el, em, en, ep, er, es, et, ew, fe, ff, ft, ge, gg, gn, ht, ia, ib, ic, id, ie, if, ig, il, im, in, ip, ir, is, it, iv, ix, iz, ke, ks, ld, le, li, ll, ly, me, mo, na, nd, ne, nt, od, og, ol, om, on, oo, op, or, os, ot, ou, ow, oy, pe, ph, pl, pp, ps, pt, qu, ra, re, ri, ro, ru, ry, se, so, ...]  \n",
       "4                                                                                                                                                                                                           [▁ab, ▁ac, ▁ad, ▁af, ▁ag, ▁ah, ▁al, ▁am, ▁an, ▁ap, ▁ar, ▁as, ▁at, ▁be, ▁bl, ▁bo, ▁br, ▁bu, ▁by, ▁ca, ▁ch, ▁cl, ▁co, ▁cr, ▁de, ▁do, ▁dr, ▁ed, ▁el, ▁em, ▁en, ▁es, ▁eu, ▁ev, ▁ex, ▁fa, ▁fe, ▁fl, ▁fo, ▁fr, ▁gl, ▁go, ▁gr, ▁gu, ▁ha, ▁he, ▁ho, ▁hu, ▁if, ▁im, ▁in, ▁is, ▁it, ▁jo, ▁ke, ▁kn, ▁la, ▁le, ▁li, ▁lo, ▁ma, ▁me, ▁mo, ▁mr, ▁mu, ▁my, ▁ne, ▁no, ▁ob, ▁of, ▁oh, ▁ok, ▁on, ▁op, ▁or, ▁pa, ▁pe, ▁ph, ▁pl, ▁po, ▁pr, ▁qu, ▁ra, ▁re, ▁ro, ▁sa, ▁sc, ▁se, ▁sh, ▁sk, ▁sl, ▁sm, ▁so, ▁sp, ▁st, ▁su, ▁sy, ▁ta, ▁te, ▁th, ...]  \n",
       "5                                                                                                                                                                                                           [ace, ach, ack, act, ade, ady, age, ail, aim, ain, all, als, ame, and, ang, ank, ans, ant, ard, are, ark, ars, art, ary, ase, ash, ass, ast, ate, ath, ave, ber, ble, ced, ces, con, cri, cus, day, der, ead, ect, ell, ens, ent, ere, erm, ers, ert, ess, est, ets, ety, ful, ger, her, hip, ial, ian, ice, ich, ick, ics, ict, ide, ied, ies, iew, iff, igh, ign, ild, ile, ill, ily, ind, ine, ing, ink, int, ion, ire, ise, ish, iss, ist, ite, ith, its, itt, ity, ive, ize, kes, led, les, lic, lud, nce, nds, ...]  \n",
       "6                                                                                                       [▁acc, ▁act, ▁add, ▁adv, ▁all, ▁and, ▁any, ▁app, ▁are, ▁arg, ▁art, ▁ask, ▁ass, ▁att, ▁aut, ▁bas, ▁bec, ▁beg, ▁beh, ▁bel, ▁bet, ▁big, ▁bit, ▁bra, ▁bre, ▁bus, ▁but, ▁can, ▁car, ▁che, ▁cle, ▁col, ▁com, ▁con, ▁cor, ▁cou, ▁cre, ▁cur, ▁day, ▁dec, ▁def, ▁des, ▁det, ▁did, ▁dis, ▁don, ▁ear, ▁eas, ▁eff, ▁ele, ▁end, ▁eng, ▁ent, ▁exp, ▁ext, ▁fam, ▁far, ▁few, ▁fin, ▁fir, ▁for, ▁fun, ▁gen, ▁get, ▁god, ▁got, ▁gra, ▁had, ▁has, ▁hel, ▁her, ▁him, ▁his, ▁hon, ▁how, ▁hum, ▁ide, ▁imp, ▁inc, ▁ind, ▁inf, ▁ins, ▁int, ▁inv, ▁iss, ▁its, ▁jud, ▁lar, ▁law, ▁leg, ▁let, ▁loc, ▁lot, ▁man, ▁mar, ▁may, ▁med, ▁mem, ▁met, ▁min, ...]  \n",
       "7                                                                                                                                                                                                                                                                  [able, ably, aint, ally, alth, ance, ange, arch, ason, atch, ated, ater, ates, ause, blem, body, cept, cess, cial, ence, ense, ents, enty, ered, eric, ever, fore, form, hing, ible, ical, ices, ient, ific, ight, ines, ings, ions, ious, ited, ject, king, llow, ment, nder, ness, ning, olog, oney, onna, osed, ough, ould, ound, ount, ouse, ower, pect, ract, reat, ress, ross, self, stem, ther, ting, ular, ures, vern, vers, very, ving, ward, ways, ween]  \n",
       "8   [▁able, ▁also, ▁appe, ▁away, ▁back, ▁been, ▁best, ▁book, ▁both, ▁call, ▁came, ▁care, ▁case, ▁cent, ▁char, ▁coll, ▁come, ▁comm, ▁comp, ▁conc, ▁conf, ▁cons, ▁cont, ▁cour, ▁didn, ▁diff, ▁dire, ▁dist, ▁does, ▁done, ▁down, ▁each, ▁even, ▁ever, ▁exam, ▁expl, ▁fact, ▁feel, ▁find, ▁five, ▁form, ▁four, ▁frie, ▁from, ▁full, ▁give, ▁good, ▁hand, ▁happ, ▁hard, ▁have, ▁head, ▁hear, ▁help, ▁here, ▁high, ▁home, ▁hund, ▁inst, ▁into, ▁just, ▁keep, ▁kind, ▁know, ▁last, ▁lead, ▁lear, ▁left, ▁life, ▁like, ▁list, ▁long, ▁look, ▁love, ▁made, ▁make, ▁many, ▁mark, ▁mean, ▁miss, ▁more, ▁most, ▁move, ▁much, ▁must, ▁name, ▁need, ▁next, ▁okay, ▁once, ▁only, ▁open, ▁over, ▁part, ▁pass, ▁peop, ▁pers, ▁plan, ▁play, ▁poss, ...]  \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [ately, ather, ating, ation, ative, atter, ature, ction, erest, ether, ident, ility, iness, ision, ities, ition, ittle, ments, other, ought, ready, thing, ually, uring, ution, velop]  \n",
       "10                                                                                                                                                   [▁about, ▁after, ▁again, ▁allow, ▁being, ▁belie, ▁build, ▁child, ▁claim, ▁clear, ▁could, ▁count, ▁court, ▁creat, ▁doesn, ▁doing, ▁eight, ▁every, ▁exper, ▁first, ▁found, ▁gener, ▁going, ▁gonna, ▁great, ▁house, ▁inter, ▁light, ▁maybe, ▁means, ▁might, ▁money, ▁never, ▁order, ▁other, ▁place, ▁point, ▁power, ▁produ, ▁quest, ▁right, ▁small, ▁somet, ▁stand, ▁start, ▁state, ▁still, ▁thank, ▁their, ▁there, ▁these, ▁thing, ▁think, ▁those, ▁thous, ▁three, ▁today, ▁trans, ▁under, ▁using, ▁video, ▁watch, ▁water, ▁where, ▁which, ▁while, ▁whole, ▁world, ▁would, ▁years]  \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [ations, ention, ertain, ically, idence]  \n",
       "12                                                                                                                                                                                                                                                                                                                                         [▁<UNK>▁, ▁always, ▁americ, ▁around, ▁before, ▁better, ▁called, ▁change, ▁commun, ▁compan, ▁comple, ▁consid, ▁contin, ▁course, ▁enough, ▁experi, ▁family, ▁follow, ▁govern, ▁happen, ▁having, ▁import, ▁includ, ▁inform, ▁little, ▁making, ▁number, ▁partic, ▁people, ▁person, ▁pretty, ▁really, ▁reason, ▁record, ▁saying, ▁school, ▁second, ▁should, ▁system, ▁things, ▁though, ▁trying]  \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [ational]  \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [▁already, ▁another, ▁because, ▁believe, ▁between, ▁certain, ▁develop, ▁differe, ▁example, ▁getting, ▁hundred, ▁looking, ▁problem, ▁process, ▁support, ▁thought, ▁through, ▁underst, ▁whether, ▁without, ▁working]  \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [▁actually, ▁anything, ▁business, ▁interest, ▁probably, ▁question, ▁thousand, ▁together]  \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [▁different, ▁important, ▁something]  \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [▁everything, ▁government, ▁understand]  \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [▁information]  \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocabulary(\"Parakeet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>nchars</th>\n",
       "      <th>start</th>\n",
       "      <th>#tokens</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#…</td>\n",
       "      <td>40</td>\n",
       "      <td>[', -, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, à, â, ç, è, é, ê, ë, î, ï, ô, ù, û]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>▶</td>\n",
       "      <td>26</td>\n",
       "      <td>[▁a, ▁b, ▁c, ▁d, ▁e, ▁f, ▁g, ▁h, ▁i, ▁j, ▁k, ▁l, ▁m, ▁n, ▁o, ▁p, ▁r, ▁s, ▁t, ▁u, ▁v, ▁w, ▁y, ▁z, ▁à, ▁é]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>#…</td>\n",
       "      <td>125</td>\n",
       "      <td>[ab, ac, ad, ag, ai, al, am, an, ap, ar, as, at, au, av, ay, aî, be, ce, ch, ci, ct, cu, cé, de, di, du, dé, el, em, en, er, es, eu, ez, ff, fi, fs, ge, gn, gu, ic, ie, if, ig, il, im, in, ir, is, it, je, la, le, li, ll, lo, ls, là, lè, lé, mb, me, mi, mp, mé, ne, ob, oc, og, oi, ol, om, on, op, or, os, ot, ou, oy, pe, ph, pp, pr, pt, qu, ra, re, ri, ré, se, si, ta, te, th, ti, tr, ts, tt, tu, té, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>▶</td>\n",
       "      <td>110</td>\n",
       "      <td>[▁ab, ▁ac, ▁ad, ▁ag, ▁ah, ▁ai, ▁al, ▁am, ▁an, ▁ap, ▁ar, ▁as, ▁au, ▁av, ▁ba, ▁be, ▁bi, ▁bl, ▁br, ▁ca, ▁ce, ▁ch, ▁cl, ▁co, ▁cr, ▁cô, ▁de, ▁di, ▁dr, ▁du, ▁dé, ▁en, ▁es, ▁et, ▁eu, ▁ex, ▁fa, ▁fi, ▁fr, ▁gr, ▁he, ▁hm, ▁id, ▁il, ▁im, ▁in, ▁je, ▁ju, ▁la, ▁le, ▁li, ▁lu, ▁là, ▁ma, ▁me, ▁mi, ▁mo, ▁mé, ▁ne, ▁ni, ▁no, ▁né, ▁ob, ▁oc, ▁oh, ▁on, ▁op, ▁or, ▁ou, ▁où, ▁pa, ▁pe, ▁ph, ▁pi, ▁pl, ▁po, ▁pr, ▁qu, ▁ra, ▁re, ▁ri, ▁ré, ▁sa, ▁sc, ▁se, ▁si, ▁so, ▁sp, ▁st, ▁su, ▁sy, ▁sé, ▁sû, ▁ta, ▁te, ▁th, ▁ti, ▁tr, ▁tu, ▁té, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>#…</td>\n",
       "      <td>151</td>\n",
       "      <td>[ace, act, age, agn, ain, ais, ait, ale, all, ame, anc, and, ang, ans, ant, ard, ari, ass, ati, ats, aut, aux, ble, bre, cer, ces, che, ché, cin, cip, cle, cti, cul, dem, der, des, dre, end, ens, ent, ers, ert, euf, eur, eux, gne, hui, ici, ien, ier, ies, ign, ill, ine, ing, ins, ion, ise, iss, ist, itu, ité, jet, ler, les, lic, lig, lle, lui, mer, mes, min, mis, mps, ner, nes, oin, oir, ois, oit, ole, olu, omb, omp, ond, one, ong, onn, ons, ont, ord, ore, orm, ors, ort, ose, oup, our, ous, out, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>▶</td>\n",
       "      <td>166</td>\n",
       "      <td>[▁acc, ▁aff, ▁ain, ▁all, ▁ann, ▁ans, ▁app, ▁arr, ▁ass, ▁att, ▁auc, ▁aus, ▁aut, ▁aux, ▁ave, ▁bah, ▁ben, ▁bes, ▁bon, ▁bou, ▁cap, ▁car, ▁cas, ▁ces, ▁cet, ▁cha, ▁che, ▁cin, ▁cli, ▁com, ▁con, ▁cor, ▁cou, ▁cré, ▁dem, ▁der, ▁des, ▁dev, ▁dis, ▁dit, ▁dix, ▁don, ▁dou, ▁déb, ▁déc, ▁déf, ▁déj, ▁dém, ▁dép, ▁eff, ▁emp, ▁enc, ▁enf, ▁ens, ▁ent, ▁env, ▁esp, ▁ess, ▁est, ▁euh, ▁eur, ▁eux, ▁exe, ▁exp, ▁fam, ▁fem, ▁fer, ▁fil, ▁fin, ▁fon, ▁for, ▁fut, ▁gra, ▁gén, ▁hab, ▁hom, ▁hum, ▁ici, ▁ils, ▁imp, ▁inc, ▁inf, ▁ins, ▁jam, ▁jou, ▁jus, ▁les, ▁lui, ▁mad, ▁mal, ▁man, ▁mar, ▁mer, ▁mes, ▁mil, ▁min, ▁mis, ▁moi, ▁mom, ▁mon, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>#…</td>\n",
       "      <td>88</td>\n",
       "      <td>[able, ages, agne, aine, ains, aire, aiss, ales, alis, ance, ande, ange, anis, ante, ants, arde, asse, atre, cher, ches, coup, dent, duit, elle, ence, ends, enir, enne, ense, ente, ents, eure, eurs, euse, iens, ille, ingt, ions, ique, iste, iter, ités, ième, ière, jour, lier, lles, lopp, mble, ment, mple, nent, oins, oire, olog, onne, onom, orte, orti, oses, otre, ours, ouve, près, puis, quer, ques, quoi, rais, rait, rent, ress, sion, tant, tion, tout, tres, ttre, uite, ures, veau, vent, vers, voir, vous, ères, êtes, être]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>▶</td>\n",
       "      <td>134</td>\n",
       "      <td>[▁alle, ▁appr, ▁arri, ▁avec, ▁avez, ▁beau, ▁bien, ▁cela, ▁cent, ▁cert, ▁ceux, ▁char, ▁cher, ▁chez, ▁cinq, ▁comb, ▁comm, ▁comp, ▁conc, ▁conf, ▁conn, ▁cons, ▁cont, ▁coup, ▁cour, ▁côté, ▁dans, ▁dern, ▁deux, ▁dieu, ▁diff, ▁dire, ▁doit, ▁donc, ▁donn, ▁dont, ▁déjà, ▁effe, ▁elle, ▁ense, ▁fais, ▁fait, ▁faut, ▁fois, ▁fond, ▁form, ▁fran, ▁gens, ▁gros, ▁hein, ▁hist, ▁indi, ▁inté, ▁jour, ▁leur, ▁long, ▁lors, ▁main, ▁mais, ▁mois, ▁mont, ▁mort, ▁même, ▁neuf, ▁nous, ▁parf, ▁part, ▁pass, ▁pays, ▁pens, ▁pers, ▁peti, ▁peut, ▁peux, ▁plan, ▁plus, ▁plut, ▁poin, ▁poli, ▁pour, ▁pouv, ▁pres, ▁prin, ▁pris, ▁prob, ▁prof, ▁prop, ▁prés, ▁puis, ▁quar, ▁quel, ▁ques, ▁quoi, ▁rais, ▁rapp, ▁repr, ▁retr, ▁rien, ▁sain, ▁sais, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>#…</td>\n",
       "      <td>25</td>\n",
       "      <td>[ables, aient, aines, aires, alité, ances, anger, ation, ature, ction, endre, eures, ieurs, ilité, iques, jourd, jours, lique, ments, ouver, ouvez, sible, sieur, tions, tique]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>▶</td>\n",
       "      <td>65</td>\n",
       "      <td>[▁ainsi, ▁aller, ▁allez, ▁alors, ▁après, ▁assez, ▁aussi, ▁autre, ▁avais, ▁avait, ▁avant, ▁avoir, ▁avons, ▁bonne, ▁celui, ▁cette, ▁chose, ▁cinqu, ▁comme, ▁compr, ▁contr, ▁crois, ▁droit, ▁elles, ▁enfin, ▁entre, ▁europ, ▁faire, ▁franç, ▁grand, ▁heure, ▁homme, ▁inter, ▁jours, ▁jusqu, ▁juste, ▁leurs, ▁mieux, ▁mille, ▁milli, ▁moins, ▁monde, ▁notre, ▁nouve, ▁ouais, ▁parce, ▁parle, ▁parti, ▁passe, ▁pense, ▁perme, ▁petit, ▁place, ▁point, ▁premi, ▁quand, ▁temps, ▁toute, ▁trans, ▁trois, ▁vidéo, ▁vingt, ▁voilà, ▁votre, ▁était]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>#…</td>\n",
       "      <td>11</td>\n",
       "      <td>[amment, ations, atique, endant, lement, lleurs, nement, sition, tement, velopp, vement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>▶</td>\n",
       "      <td>41</td>\n",
       "      <td>[▁&lt;UNK&gt;▁, ▁accord, ▁années, ▁autres, ▁besoin, ▁chaque, ▁choses, ▁commen, ▁commun, ▁compte, ▁contin, ▁contre, ▁demand, ▁depuis, ▁différ, ▁donner, ▁encore, ▁europé, ▁france, ▁grande, ▁import, ▁jamais, ▁mettre, ▁moment, ▁niveau, ▁nombre, ▁parler, ▁partie, ▁passer, ▁petite, ▁pouvez, ▁quatre, ▁regard, ▁répond, ▁savoir, ▁simple, ▁toutes, ▁travai, ▁trente, ▁trouve, ▁utilis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>#…</td>\n",
       "      <td>2</td>\n",
       "      <td>[alement, llement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>▶</td>\n",
       "      <td>19</td>\n",
       "      <td>[▁appelle, ▁aujourd, ▁comment, ▁enfants, ▁ensuite, ▁entrepr, ▁exemple, ▁mainten, ▁pendant, ▁personn, ▁pouvoir, ▁premier, ▁prendre, ▁présent, ▁quelque, ▁souvent, ▁surtout, ▁travail, ▁étaient]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>▶</td>\n",
       "      <td>14</td>\n",
       "      <td>[▁ailleurs, ▁beaucoup, ▁fonction, ▁français, ▁histoire, ▁monsieur, ▁personne, ▁pourquoi, ▁première, ▁quelques, ▁question, ▁soixante, ▁toujours, ▁vraiment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>▶</td>\n",
       "      <td>5</td>\n",
       "      <td>[▁cinquante, ▁important, ▁personnes, ▁plusieurs, ▁également]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁maintenant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td></td>\n",
       "      <td>1024</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nchars start  #tokens  \\\n",
       "0       0   ▶       1      \n",
       "1       1  #…      40      \n",
       "2       1   ▶      26      \n",
       "3       2  #…     125      \n",
       "4       2   ▶     110      \n",
       "5       3  #…     151      \n",
       "6       3   ▶     166      \n",
       "7       4  #…      88      \n",
       "8       4   ▶     134      \n",
       "9       5  #…      25      \n",
       "10      5   ▶      65      \n",
       "11      6  #…      11      \n",
       "12      6   ▶      41      \n",
       "13      7  #…       2      \n",
       "14      7   ▶      19      \n",
       "15      8   ▶      14      \n",
       "16      9   ▶       5      \n",
       "17     10   ▶       1      \n",
       "18  TOTAL        1024      \n",
       "\n",
       "   tokens                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [▁]  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [', -, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, à, â, ç, è, é, ê, ë, î, ï, ô, ù, û]  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [▁a, ▁b, ▁c, ▁d, ▁e, ▁f, ▁g, ▁h, ▁i, ▁j, ▁k, ▁l, ▁m, ▁n, ▁o, ▁p, ▁r, ▁s, ▁t, ▁u, ▁v, ▁w, ▁y, ▁z, ▁à, ▁é]  \n",
       "3                                                                                                                                                                                                                                                                                                               [ab, ac, ad, ag, ai, al, am, an, ap, ar, as, at, au, av, ay, aî, be, ce, ch, ci, ct, cu, cé, de, di, du, dé, el, em, en, er, es, eu, ez, ff, fi, fs, ge, gn, gu, ic, ie, if, ig, il, im, in, ir, is, it, je, la, le, li, ll, lo, ls, là, lè, lé, mb, me, mi, mp, mé, ne, ob, oc, og, oi, ol, om, on, op, or, os, ot, ou, oy, pe, ph, pp, pr, pt, qu, ra, re, ri, ré, se, si, ta, te, th, ti, tr, ts, tt, tu, té, ...]  \n",
       "4                                                                                                                                                                                                           [▁ab, ▁ac, ▁ad, ▁ag, ▁ah, ▁ai, ▁al, ▁am, ▁an, ▁ap, ▁ar, ▁as, ▁au, ▁av, ▁ba, ▁be, ▁bi, ▁bl, ▁br, ▁ca, ▁ce, ▁ch, ▁cl, ▁co, ▁cr, ▁cô, ▁de, ▁di, ▁dr, ▁du, ▁dé, ▁en, ▁es, ▁et, ▁eu, ▁ex, ▁fa, ▁fi, ▁fr, ▁gr, ▁he, ▁hm, ▁id, ▁il, ▁im, ▁in, ▁je, ▁ju, ▁la, ▁le, ▁li, ▁lu, ▁là, ▁ma, ▁me, ▁mi, ▁mo, ▁mé, ▁ne, ▁ni, ▁no, ▁né, ▁ob, ▁oc, ▁oh, ▁on, ▁op, ▁or, ▁ou, ▁où, ▁pa, ▁pe, ▁ph, ▁pi, ▁pl, ▁po, ▁pr, ▁qu, ▁ra, ▁re, ▁ri, ▁ré, ▁sa, ▁sc, ▁se, ▁si, ▁so, ▁sp, ▁st, ▁su, ▁sy, ▁sé, ▁sû, ▁ta, ▁te, ▁th, ▁ti, ▁tr, ▁tu, ▁té, ...]  \n",
       "5                                                                                                                                                                                                           [ace, act, age, agn, ain, ais, ait, ale, all, ame, anc, and, ang, ans, ant, ard, ari, ass, ati, ats, aut, aux, ble, bre, cer, ces, che, ché, cin, cip, cle, cti, cul, dem, der, des, dre, end, ens, ent, ers, ert, euf, eur, eux, gne, hui, ici, ien, ier, ies, ign, ill, ine, ing, ins, ion, ise, iss, ist, itu, ité, jet, ler, les, lic, lig, lle, lui, mer, mes, min, mis, mps, ner, nes, oin, oir, ois, oit, ole, olu, omb, omp, ond, one, ong, onn, ons, ont, ord, ore, orm, ors, ort, ose, oup, our, ous, out, ...]  \n",
       "6                                                                                                       [▁acc, ▁aff, ▁ain, ▁all, ▁ann, ▁ans, ▁app, ▁arr, ▁ass, ▁att, ▁auc, ▁aus, ▁aut, ▁aux, ▁ave, ▁bah, ▁ben, ▁bes, ▁bon, ▁bou, ▁cap, ▁car, ▁cas, ▁ces, ▁cet, ▁cha, ▁che, ▁cin, ▁cli, ▁com, ▁con, ▁cor, ▁cou, ▁cré, ▁dem, ▁der, ▁des, ▁dev, ▁dis, ▁dit, ▁dix, ▁don, ▁dou, ▁déb, ▁déc, ▁déf, ▁déj, ▁dém, ▁dép, ▁eff, ▁emp, ▁enc, ▁enf, ▁ens, ▁ent, ▁env, ▁esp, ▁ess, ▁est, ▁euh, ▁eur, ▁eux, ▁exe, ▁exp, ▁fam, ▁fem, ▁fer, ▁fil, ▁fin, ▁fon, ▁for, ▁fut, ▁gra, ▁gén, ▁hab, ▁hom, ▁hum, ▁ici, ▁ils, ▁imp, ▁inc, ▁inf, ▁ins, ▁jam, ▁jou, ▁jus, ▁les, ▁lui, ▁mad, ▁mal, ▁man, ▁mar, ▁mer, ▁mes, ▁mil, ▁min, ▁mis, ▁moi, ▁mom, ▁mon, ...]  \n",
       "7                                                                                                                                                                                    [able, ages, agne, aine, ains, aire, aiss, ales, alis, ance, ande, ange, anis, ante, ants, arde, asse, atre, cher, ches, coup, dent, duit, elle, ence, ends, enir, enne, ense, ente, ents, eure, eurs, euse, iens, ille, ingt, ions, ique, iste, iter, ités, ième, ière, jour, lier, lles, lopp, mble, ment, mple, nent, oins, oire, olog, onne, onom, orte, orti, oses, otre, ours, ouve, près, puis, quer, ques, quoi, rais, rait, rent, ress, sion, tant, tion, tout, tres, ttre, uite, ures, veau, vent, vers, voir, vous, ères, êtes, être]  \n",
       "8   [▁alle, ▁appr, ▁arri, ▁avec, ▁avez, ▁beau, ▁bien, ▁cela, ▁cent, ▁cert, ▁ceux, ▁char, ▁cher, ▁chez, ▁cinq, ▁comb, ▁comm, ▁comp, ▁conc, ▁conf, ▁conn, ▁cons, ▁cont, ▁coup, ▁cour, ▁côté, ▁dans, ▁dern, ▁deux, ▁dieu, ▁diff, ▁dire, ▁doit, ▁donc, ▁donn, ▁dont, ▁déjà, ▁effe, ▁elle, ▁ense, ▁fais, ▁fait, ▁faut, ▁fois, ▁fond, ▁form, ▁fran, ▁gens, ▁gros, ▁hein, ▁hist, ▁indi, ▁inté, ▁jour, ▁leur, ▁long, ▁lors, ▁main, ▁mais, ▁mois, ▁mont, ▁mort, ▁même, ▁neuf, ▁nous, ▁parf, ▁part, ▁pass, ▁pays, ▁pens, ▁pers, ▁peti, ▁peut, ▁peux, ▁plan, ▁plus, ▁plut, ▁poin, ▁poli, ▁pour, ▁pouv, ▁pres, ▁prin, ▁pris, ▁prob, ▁prof, ▁prop, ▁prés, ▁puis, ▁quar, ▁quel, ▁ques, ▁quoi, ▁rais, ▁rapp, ▁repr, ▁retr, ▁rien, ▁sain, ▁sais, ...]  \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [ables, aient, aines, aires, alité, ances, anger, ation, ature, ction, endre, eures, ieurs, ilité, iques, jourd, jours, lique, ments, ouver, ouvez, sible, sieur, tions, tique]  \n",
       "10                                                                                                                                                                                           [▁ainsi, ▁aller, ▁allez, ▁alors, ▁après, ▁assez, ▁aussi, ▁autre, ▁avais, ▁avait, ▁avant, ▁avoir, ▁avons, ▁bonne, ▁celui, ▁cette, ▁chose, ▁cinqu, ▁comme, ▁compr, ▁contr, ▁crois, ▁droit, ▁elles, ▁enfin, ▁entre, ▁europ, ▁faire, ▁franç, ▁grand, ▁heure, ▁homme, ▁inter, ▁jours, ▁jusqu, ▁juste, ▁leurs, ▁mieux, ▁mille, ▁milli, ▁moins, ▁monde, ▁notre, ▁nouve, ▁ouais, ▁parce, ▁parle, ▁parti, ▁passe, ▁pense, ▁perme, ▁petit, ▁place, ▁point, ▁premi, ▁quand, ▁temps, ▁toute, ▁trans, ▁trois, ▁vidéo, ▁vingt, ▁voilà, ▁votre, ▁était]  \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [amment, ations, atique, endant, lement, lleurs, nement, sition, tement, velopp, vement]  \n",
       "12                                                                                                                                                                                                                                                                                                                                                  [▁<UNK>▁, ▁accord, ▁années, ▁autres, ▁besoin, ▁chaque, ▁choses, ▁commen, ▁commun, ▁compte, ▁contin, ▁contre, ▁demand, ▁depuis, ▁différ, ▁donner, ▁encore, ▁europé, ▁france, ▁grande, ▁import, ▁jamais, ▁mettre, ▁moment, ▁niveau, ▁nombre, ▁parler, ▁partie, ▁passer, ▁petite, ▁pouvez, ▁quatre, ▁regard, ▁répond, ▁savoir, ▁simple, ▁toutes, ▁travai, ▁trente, ▁trouve, ▁utilis]  \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [alement, llement]  \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [▁appelle, ▁aujourd, ▁comment, ▁enfants, ▁ensuite, ▁entrepr, ▁exemple, ▁mainten, ▁pendant, ▁personn, ▁pouvoir, ▁premier, ▁prendre, ▁présent, ▁quelque, ▁souvent, ▁surtout, ▁travail, ▁étaient]  \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [▁ailleurs, ▁beaucoup, ▁fonction, ▁français, ▁histoire, ▁monsieur, ▁personne, ▁pourquoi, ▁première, ▁quelques, ▁question, ▁soixante, ▁toujours, ▁vraiment]  \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [▁cinquante, ▁important, ▁personnes, ▁plusieurs, ▁également]  \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [▁maintenant]  \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocabulary(\"🐦 Perruche\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"examples\">🔬🕹️ See how tokenizers do tokenize texts</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>size</th>\n",
       "      <th>#tokens</th>\n",
       "      <th>fert.</th>\n",
       "      <th>round-trip</th>\n",
       "      <th>comment</th>\n",
       "      <th>encoded tokens</th>\n",
       "      <th>decoded text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT 3.5</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>11</td>\n",
       "      <td>1.8</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!</td>\n",
       "      <td>Mais, mais… vas t'en là-bas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>11</td>\n",
       "      <td>1.8</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!</td>\n",
       "      <td>Mais, mais… vas t'en là-bas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃▁en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>256k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt;Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phi 2</td>\n",
       "      <td>50.3k</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>❌</td>\n",
       "      <td>«▁» removed (char 28/29)</td>\n",
       "      <td>M┃ais┃,┃▁m┃ais┃…┃▁vas┃▁t┃'┃en┃▁l┃à┃-┃bas┃▁!</td>\n",
       "      <td>Mais, mais… vas t'en là-bas!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phi 3</td>\n",
       "      <td>32k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>11</td>\n",
       "      <td>1.8</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!</td>\n",
       "      <td>Mais, mais… vas t'en là-bas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Falcon</td>\n",
       "      <td>65k</td>\n",
       "      <td>13</td>\n",
       "      <td>2.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁┃!</td>\n",
       "      <td>Mais, mais… vas t'en là-bas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mistral</td>\n",
       "      <td>32.8k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama 2</td>\n",
       "      <td>32k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>11</td>\n",
       "      <td>1.8</td>\n",
       "      <td>❌</td>\n",
       "      <td>«▁» removed (char 28/29)</td>\n",
       "      <td>&lt;BOS&gt;┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!</td>\n",
       "      <td>&lt;BOS&gt;Mais, mais… vas t'en là-bas!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>❌</td>\n",
       "      <td>«…» ≠ «...»</td>\n",
       "      <td>&lt;BOS&gt;┃▁Mais,┃▁mais┃...┃▁vas┃▁t'┃en┃▁là┃-bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; Mais, mais... vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>Mais┃,┃▁mais┃…┃▁vas┃▁t'en┃▁là-bas┃▁!</td>\n",
       "      <td>Mais, mais… vas t'en là-bas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Olmo 2</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!</td>\n",
       "      <td>Mais, mais… vas t'en là-bas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C4</td>\n",
       "      <td>255k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt;Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aya</td>\n",
       "      <td>255k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt;Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Jais</td>\n",
       "      <td>64k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>14</td>\n",
       "      <td>2.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁Mais┃,┃▁mais┃�┃�┃�┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>32k</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; Mais, mais… vas t'en là-bas !&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Whisper</td>\n",
       "      <td>50.3k</td>\n",
       "      <td>14</td>\n",
       "      <td>2.3</td>\n",
       "      <td>❌</td>\n",
       "      <td>«▁» removed (char 28/29)</td>\n",
       "      <td>&lt;BOS&gt;┃&lt;notimestamps&gt;┃M┃ais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt;&lt;notimestamps&gt;Mais, mais… vas t'en là-bas!&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Parakeet</td>\n",
       "      <td>1024</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>❌</td>\n",
       "      <td>OOV</td>\n",
       "      <td>&lt;BOS&gt;┃ma┃is┃▁&lt;UNK&gt;▁┃ma┃is┃▁&lt;UNK&gt;▁┃v┃as┃t┃'┃en┃l┃▁&lt;UNK&gt;▁┃b┃as┃┃▁&lt;UNK&gt;▁┃&lt;SOS&gt;</td>\n",
       "      <td>mais &lt;UNK&gt;  mais &lt;UNK&gt;  vas t'en l &lt;UNK&gt; bas  &lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>🐦 Perruche</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>2.7</td>\n",
       "      <td>❌</td>\n",
       "      <td>OOV</td>\n",
       "      <td>&lt;BOS&gt;┃mais┃▁&lt;UNK&gt;▁┃mais┃▁&lt;UNK&gt;▁┃v┃as┃t┃'┃en┃là┃-┃b┃as┃┃▁&lt;UNK&gt;▁┃&lt;SOS&gt;</td>\n",
       "      <td>mais &lt;UNK&gt;  mais &lt;UNK&gt;  vas t'en là-bas  &lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenizer   size     #tokens  fert. round-trip comment                    \\\n",
       "0      GPT 3.5  100.3k  11       1.8    ✅                                     \n",
       "1        GPT 4  100.3k  11       1.8    ✅                                     \n",
       "2        Lucie     65k  12       2.0    ✅                                     \n",
       "3        Gemma    256k  12       2.0    ✅                                     \n",
       "4        Phi 2   50.3k  15       2.5    ❌          «▁» removed (char 28/29)   \n",
       "5        Phi 3     32k  12       2.0    ✅                                     \n",
       "6         Qwen  151.6k  11       1.8    ✅                                     \n",
       "7       Falcon     65k  13       2.2    ✅                                     \n",
       "8      Mistral   32.8k  12       2.0    ✅                                     \n",
       "9      Llama 2     32k  12       2.0    ✅                                     \n",
       "10     Llama 3    128k  11       1.8    ❌          «▁» removed (char 28/29)   \n",
       "11   Croissant     32k   9       1.5    ❌                       «…» ≠ «...»   \n",
       "12       Bloom  250.7k   8       1.3    ✅                                     \n",
       "13      Olmo 2  100.3k  12       2.0    ✅                                     \n",
       "14          C4    255k  12       2.0    ✅                                     \n",
       "15         Aya    255k  12       2.0    ✅                                     \n",
       "16        Jais     64k  12       2.0    ✅                                     \n",
       "17     EuroLLM    128k  14       2.3    ✅                                     \n",
       "18      Zephyr     32k  12       2.0    ✅                                     \n",
       "19     Whisper   50.3k  14       2.3    ❌          «▁» removed (char 28/29)   \n",
       "20    Parakeet    1024  18       3.0    ❌                               OOV   \n",
       "21  🐦 Perruche    1024  16       2.7    ❌                               OOV   \n",
       "\n",
       "   encoded tokens                                                                \\\n",
       "0                                       Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!   \n",
       "1                                       Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!   \n",
       "2                        <BOS>┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃▁en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "3                          <BOS>┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "4                                   M┃ais┃,┃▁m┃ais┃…┃▁vas┃▁t┃'┃en┃▁l┃à┃-┃bas┃▁!   \n",
       "5                               ▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "6                                       Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!   \n",
       "7                                     Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁┃!   \n",
       "8                         <BOS>┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "9                         <BOS>┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "10                                <BOS>┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'en┃▁là┃-b┃as┃▁!   \n",
       "11                         <BOS>┃▁Mais,┃▁mais┃...┃▁vas┃▁t'┃en┃▁là┃-bas┃▁!┃<EOS>   \n",
       "12                                         Mais┃,┃▁mais┃…┃▁vas┃▁t'en┃▁là-bas┃▁!   \n",
       "13                                     Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!   \n",
       "14                         <BOS>┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "15                         <BOS>┃Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "16                        <BOS>┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "17                    <BOS>┃▁Mais┃,┃▁mais┃�┃�┃�┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "18                        <BOS>┃▁Mais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "19         <BOS>┃<notimestamps>┃M┃ais┃,┃▁mais┃…┃▁vas┃▁t┃'┃en┃▁là┃-┃bas┃▁!┃<EOS>   \n",
       "20  <BOS>┃ma┃is┃▁<UNK>▁┃ma┃is┃▁<UNK>▁┃v┃as┃t┃'┃en┃l┃▁<UNK>▁┃b┃as┃┃▁<UNK>▁┃<SOS>   \n",
       "21         <BOS>┃mais┃▁<UNK>▁┃mais┃▁<UNK>▁┃v┃as┃t┃'┃en┃là┃-┃b┃as┃┃▁<UNK>▁┃<SOS>   \n",
       "\n",
       "   decoded text                                           \n",
       "0                          Mais, mais… vas t'en là-bas !  \n",
       "1                          Mais, mais… vas t'en là-bas !  \n",
       "2               <BOS> Mais, mais… vas t'en là-bas !<EOS>  \n",
       "3                <BOS>Mais, mais… vas t'en là-bas !<EOS>  \n",
       "4                           Mais, mais… vas t'en là-bas!  \n",
       "5                     Mais, mais… vas t'en là-bas !<EOS>  \n",
       "6                          Mais, mais… vas t'en là-bas !  \n",
       "7                          Mais, mais… vas t'en là-bas !  \n",
       "8               <BOS> Mais, mais… vas t'en là-bas !<EOS>  \n",
       "9               <BOS> Mais, mais… vas t'en là-bas !<EOS>  \n",
       "10                     <BOS>Mais, mais… vas t'en là-bas!  \n",
       "11            <BOS> Mais, mais... vas t'en là-bas !<EOS>  \n",
       "12                         Mais, mais… vas t'en là-bas !  \n",
       "13                         Mais, mais… vas t'en là-bas !  \n",
       "14               <BOS>Mais, mais… vas t'en là-bas !<EOS>  \n",
       "15               <BOS>Mais, mais… vas t'en là-bas !<EOS>  \n",
       "16              <BOS> Mais, mais… vas t'en là-bas !<EOS>  \n",
       "17              <BOS> Mais, mais… vas t'en là-bas !<EOS>  \n",
       "18              <BOS> Mais, mais… vas t'en là-bas !<EOS>  \n",
       "19  <BOS><notimestamps>Mais, mais… vas t'en là-bas!<EOS>  \n",
       "20  mais <UNK>  mais <UNK>  vas t'en l <UNK> bas  <UNK>   \n",
       "21       mais <UNK>  mais <UNK>  vas t'en là-bas  <UNK>   "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokenizers(\"Mais, mais… vas t'en là-bas !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"arabic\">🔬☪ Tokenization with Arabic (and code-switching)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👀 Tokenization of the same text, with/without Right-Left (RLM) and Left-Right Marks (LRM):\n",
      "- without marks:\n",
      "‏، كيف حالك؟‎Jean-Pierre ‏مرحباً \n",
      "- with RLM/LRM marks:\n",
      "‏، كيف حالك؟‎<LRM>Jean-Pierre<RLM> ‏مرحباً ‎<RLM>\n",
      "(to be read in this order: ‎<RLM>‏مرحباً ‎<LRM>Jean-Pierre<RLM> ‏، كيف حالك؟)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>size</th>\n",
       "      <th>fert.</th>\n",
       "      <th>round-trip</th>\n",
       "      <th>comment</th>\n",
       "      <th>encoded tokens</th>\n",
       "      <th>decoded text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>without marks</td>\n",
       "      <td>Aya</td>\n",
       "      <td>255k</td>\n",
       "      <td>3.5</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>‎&lt;BOS&gt;ً┃با┃ح┃مر┃‏┃Pierre┃-┃‎▁Jean،┃‏‎▁▁يف┃ك┃‏‎▁▁؟┃ك┃حال┃‏┃‎&lt;EOS&gt;</td>\n",
       "      <td>‎&lt;EOS&gt;‏، كيف حالك؟‎Jean-Pierre ‏مرحباً ‎&lt;BOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with RLM/LRM marks</td>\n",
       "      <td>Aya</td>\n",
       "      <td>255k</td>\n",
       "      <td>4.8</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>�┃�┃‎&lt;BOS&gt;ً┃با┃ح┃مر┃‏┃�┃�┃Pierre┃-┃Jean┃‎▁&lt;LRM&gt;،┃‏‎▁▁يف┃ك┃‏‎▁▁؟┃ك┃حال┃‏┃‎&lt;EOS&gt;</td>\n",
       "      <td>‎&lt;EOS&gt;‏، كيف حالك؟‎Jean-Pierre ‏مرحباً ‎&lt;BOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>without marks</td>\n",
       "      <td>Jais</td>\n",
       "      <td>64k</td>\n",
       "      <td>3.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>‎&lt;BOS&gt;ً┃مرحبا┃‏┃Pierre┃-┃‎▁Jeanالك┃ح┃كيف┃،┃‏┃&lt;EOS&gt;┃�┃‎�</td>\n",
       "      <td>‎&lt;EOS&gt;‏، كيف حالك؟‎Jean-Pierre ‏مرحباً  ‎&lt;BOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>with RLM/LRM marks</td>\n",
       "      <td>Jais</td>\n",
       "      <td>64k</td>\n",
       "      <td>4.5</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;RLM&gt;┃▁┃‎&lt;BOS&gt;ً┃مرحبا┃‏┃&lt;RLM&gt;┃Pierre┃-┃Jean┃&lt;LRM&gt;┃‎▁الك┃ح┃كيف┃،┃‏┃&lt;EOS&gt;┃�┃‎�</td>\n",
       "      <td>‎&lt;EOS&gt;‏، كيف حالك؟‎Jean-Pierre ‏مرحباً  ‎&lt;BOS&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TEST                tokenizer size   fert. round-trip comment  \\\n",
       "1       without marks   Aya      255k  3.5    ✅                   \n",
       "3  with RLM/LRM marks   Aya      255k  4.8    ✅                   \n",
       "0       without marks  Jais       64k  3.2    ✅                   \n",
       "2  with RLM/LRM marks  Jais       64k  4.5    ✅                   \n",
       "\n",
       "  encoded tokens                                                                   \\\n",
       "1                ‎<BOS>ً┃با┃ح┃مر┃‏┃Pierre┃-┃‎▁Jean،┃‏‎▁▁يف┃ك┃‏‎▁▁؟┃ك┃حال┃‏┃‎<EOS>   \n",
       "3  �┃�┃‎<BOS>ً┃با┃ح┃مر┃‏┃�┃�┃Pierre┃-┃Jean┃‎▁<LRM>،┃‏‎▁▁يف┃ك┃‏‎▁▁؟┃ك┃حال┃‏┃‎<EOS>   \n",
       "0                         ‎<BOS>ً┃مرحبا┃‏┃Pierre┃-┃‎▁Jeanالك┃ح┃كيف┃،┃‏┃<EOS>┃�┃‎�   \n",
       "2    <RLM>┃▁┃‎<BOS>ً┃مرحبا┃‏┃<RLM>┃Pierre┃-┃Jean┃<LRM>┃‎▁الك┃ح┃كيف┃،┃‏┃<EOS>┃�┃‎�   \n",
       "\n",
       "  decoded text                                      \n",
       "1    ‎<EOS>‏، كيف حالك؟‎Jean-Pierre ‏مرحباً ‎<BOS>  \n",
       "3    ‎<EOS>‏، كيف حالك؟‎Jean-Pierre ‏مرحباً ‎<BOS>  \n",
       "0  ‎<EOS>‏، كيف حالك؟‎Jean-Pierre ‏مرحباً  ‎<BOS>   \n",
       "2  ‎<EOS>‏، كيف حالك؟‎Jean-Pierre ‏مرحباً  ‎<BOS>   "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"مرحباً Jean-Pierre، كيف حالك؟\"\n",
    "\n",
    "input_with_marks = add_rlm_and_lrm_arabic(input)\n",
    "assert input != input_with_marks\n",
    "\n",
    "print(\"👀 Tokenization of the same text, with/without Right-Left (RLM) and Left-Right Marks (LRM):\")\n",
    "print(\"- without marks:\")\n",
    "print(normalize_for_display(input))\n",
    "# print(\"(to be read in this order: \"+fix_arabic_display(input, arabic_right_to_left=False)+\")\")\n",
    "print(\"- with RLM/LRM marks:\")\n",
    "input_with_marks_escaped = input_with_marks.replace(_LRM, \"<LRM>\").replace(_RLM, \"<RLM>\")\n",
    "print(normalize_for_display(input_with_marks_escaped))\n",
    "print(\"(to be read in this order: \"+fix_arabic_display(input_with_marks_escaped, arabic_right_to_left=False)+\")\")\n",
    "\n",
    "test_tokenizers_batch({\n",
    "        \"without marks\":input,\n",
    "        \"with RLM/LRM marks\":input_with_marks\n",
    "    },\n",
    "    [\"Jais\", \"Aya\"],\n",
    "    sort_by_tokenizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"challenge\">🔬🤼 Challenge tokenizers</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the outputs of several tokenizers on particular strings to test some aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing tokenizers: 100%|██████████| 7/7 [00:48<00:00,  6.98s/test]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>size</th>\n",
       "      <th>fert.</th>\n",
       "      <th>round-trip</th>\n",
       "      <th>comment</th>\n",
       "      <th>encoded tokens</th>\n",
       "      <th>decoded text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>2.0</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>wav┃2┃vec┃▁pour┃▁1┃.┃5┃€┃▁en┃▁2024</td>\n",
       "      <td>wav2vec pour 1.5€ en 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>2.6</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃202┃4</td>\n",
       "      <td>wav2vec pour 1.5€ en 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>2.6</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>&lt;BOS&gt;┃wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃202┃4</td>\n",
       "      <td>&lt;BOS&gt;wav2vec pour 1.5€ en 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>3.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; wav2vec pour 1.5€ en 2024&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>3.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4</td>\n",
       "      <td>wav2vec pour 1.5€ en 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>32k</td>\n",
       "      <td>3.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁w┃av┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; wav2vec pour 1.5€ en 2024&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>3.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁w┃av┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; wav2vec pour 1.5€ en 2024&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIGITS</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>3.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁w┃av┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; wav2vec pour 1.5€ en 2024&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RARE</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>1.8</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>fraction┃▁½┃▁sm┃iley┃▁�┃�┃▁kat┃akana┃▁あ┃�┃�</td>\n",
       "      <td>fraction ½ smiley 😀 katakana あ゙</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RARE</td>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>2.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃fraction┃▁┃½┃▁smile┃y┃▁😀┃▁kata┃k┃ana┃▁あ┃�┃�</td>\n",
       "      <td>&lt;BOS&gt;fraction ½ smiley 😀 katakana あ゙</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RARE</td>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>2.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>fraction┃▁┃½┃▁smile┃y┃▁😀┃▁kata┃k┃ana┃▁┃あ┃�┃�</td>\n",
       "      <td>fraction ½ smiley 😀 katakana あ゙</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RARE</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>2.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>fraction┃▁┃½┃▁smile┃y┃▁😀┃▁kata┃k┃ana┃▁┃あ┃�┃�</td>\n",
       "      <td>fraction ½ smiley 😀 katakana あ゙</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RARE</td>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>2.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁fraction┃▁┃�┃�┃▁sm┃iley┃▁😀┃▁kat┃ak┃ana┃▁あ┃�┃�┃�┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; fraction ½ smiley 😀 katakana あ゙&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RARE</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>32k</td>\n",
       "      <td>2.5</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁fraction┃▁┃½┃▁smile┃y┃▁┃😀┃▁kat┃ak┃ana┃▁┃あ┃�┃�┃�┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; fraction ½ smiley 😀 katakana あ゙&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RARE</td>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>2.5</td>\n",
       "      <td>❌</td>\n",
       "      <td>«½▁smi・・・na▁あ゙» ≠ «1⁄2▁s・・・ana▁あ»</td>\n",
       "      <td>&lt;BOS&gt;┃▁fraction┃▁┃1┃⁄┃2┃▁smile┃y┃▁┃😀┃▁k┃ata┃k┃ana┃▁┃あ┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; fraction 1⁄2 smiley 😀 katakana あ&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RARE</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>3.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁fraction┃▁┃½┃▁sm┃iley┃▁┃�┃�┃�┃�┃▁k┃atak┃ana┃▁┃�┃�┃�┃�┃�┃�┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; fraction ½ smiley 😀 katakana あ゙&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MATH</td>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>8.0</td>\n",
       "      <td>❌</td>\n",
       "      <td>«²÷» ≠ «2»</td>\n",
       "      <td>&lt;BOS&gt;┃▁a.┃(b┃+┃c)┃2┃e┃×┃f┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; a.(b+c)2e×f&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MATH</td>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>10.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃a┃.(┃b┃+c┃)┃²┃÷┃e┃×┃f</td>\n",
       "      <td>&lt;BOS&gt;a.(b+c)²÷e×f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MATH</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>10.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>a┃.(┃b┃+c┃)┃²┃÷┃e┃×┃f</td>\n",
       "      <td>a.(b+c)²÷e×f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MATH</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>10.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>a┃.(┃b┃+c┃)┃²┃÷┃e┃×┃f</td>\n",
       "      <td>a.(b+c)²÷e×f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MATH</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>32k</td>\n",
       "      <td>11.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁a┃.(┃b┃+┃c┃)┃²┃÷┃e┃×┃f┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; a.(b+c)²÷e×f&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MATH</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>11.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁a┃.(┃▁b┃+┃c┃)┃²┃÷┃e┃×┃f┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; a.(b+c)²÷e×f&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MATH</td>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>11.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>a┃.(┃b┃+c┃)┃²┃�┃�┃e┃×┃f</td>\n",
       "      <td>a.(b+c)²÷e×f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MATH</td>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>12.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁a┃.(┃b┃+┃c┃)┃�┃�┃÷┃e┃×┃f┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; a.(b+c)²÷e×f&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>2.2</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>1┃▁1┃⍽┃2┃▁┃▁2┃⍽⍽┃3┃▁▁┃▁3┃⍽⍽⍽┃4┃▁▁▁┃▁4┃⍽⍽⍽⍽┃5┃▁▁▁▁┃・・・▁▁▁┃▁10┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽┃11┃▁▁▁▁▁▁▁▁▁▁┃▁11┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽⍽</td>\n",
       "      <td>1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6      6⍽⍽・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>2.5</td>\n",
       "      <td>❌</td>\n",
       "      <td>«⍽2▁▁2・・・⍽⍽⍽⍽⍽» ≠ «▁2▁▁2・・・▁▁▁▁▁»</td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃▁┃1┃▁┃2┃▁┃2┃▁┃3┃▁┃3┃▁┃4┃▁┃4┃▁┃5┃▁┃5┃▁┃6┃・・・┃9┃▁┃▁┃9┃▁┃▁┃1┃0┃▁┃▁┃1┃0┃▁┃▁┃1┃1┃▁┃▁┃1┃1┃▁┃▁┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1 1 2  2  3   3   4    4    5     5     6   ・・・       10          11           11           &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>2.9</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>&lt;BOS&gt;┃1┃▁┃1┃⍽┃2┃▁┃▁┃2┃⍽┃⍽┃3┃▁▁┃▁┃3┃⍽⍽┃⍽┃4┃▁▁▁┃▁┃4┃・・・▁▁┃▁┃10┃⍽⍽⍽⍽⍽⍽⍽⍽⍽┃⍽┃11┃▁▁▁▁▁▁▁▁▁▁┃▁┃11┃⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽</td>\n",
       "      <td>&lt;BOS&gt;1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6    ・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>3.0</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>1┃▁┃1┃⍽┃2┃▁┃▁┃2┃⍽┃⍽┃3┃▁▁┃▁┃3┃⍽⍽┃⍽┃4┃▁▁▁┃▁┃4┃⍽⍽⍽┃⍽┃・・・┃▁┃10┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽┃⍽┃11┃▁▁▁▁▁▁▁▁▁▁┃▁┃11┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽⍽</td>\n",
       "      <td>1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6      6⍽⍽・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>3.2</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>1┃▁┃1┃⍽┃2┃▁┃▁┃2┃⍽┃⍽┃3┃▁▁┃▁┃3┃⍽⍽┃⍽┃4┃▁▁▁┃▁┃4┃⍽⍽⍽┃⍽┃・・・1┃0┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽┃⍽┃1┃1┃▁▁▁▁▁▁▁▁▁▁┃▁┃1┃1┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽⍽</td>\n",
       "      <td>1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6      6⍽⍽・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>32k</td>\n",
       "      <td>4.7</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃▁┃1┃⍽┃2┃▁┃2┃⍽┃⍽┃3┃▁▁┃3┃⍽┃⍽┃⍽┃4┃▁▁▁┃4┃⍽┃⍽・・・⍽┃⍽┃1┃1┃▁▁▁▁▁▁▁▁▁▁┃1┃1┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6   ・・・       10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>7.2</td>\n",
       "      <td>❌</td>\n",
       "      <td>«⍽2▁▁2・・・⍽⍽⍽⍽⍽» ≠ «▁2▁▁2・・・▁▁▁▁▁»</td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃▁┃1┃▁┃2┃▁┃▁┃2┃▁┃▁┃3┃▁┃▁┃▁┃3┃▁┃▁┃▁┃4┃▁┃▁┃・・・┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃1┃1┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1 1 2  2  3   3   4    4    5     5     6   ・・・       10          11           11           &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SPACES</td>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>7.7</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃▁┃1┃�┃�┃2┃▁┃2┃�┃�┃�┃�┃3┃▁▁┃3┃�┃�┃�┃�┃�┃�・・・┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6   ・・・       10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>2.9</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n\\r\\n\\r\\・・・┃11┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n</td>\n",
       "      <td>1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5\\r\\n\\・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>2.9</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>&lt;BOS&gt;┃1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n\\・・・┃11┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n</td>\n",
       "      <td>&lt;BOS&gt;1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>3.1</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n\\r\\n\\r\\・・・1┃1┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n</td>\n",
       "      <td>1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5\\r\\n\\・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>3.8</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n┃\\r\\n\\r・・・1┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n</td>\n",
       "      <td>1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5\\r\\n\\・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>4.5</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n┃\\r\\n┃4┃\\r\\n\\r・・・r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n・・・1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>5.5</td>\n",
       "      <td>❌</td>\n",
       "      <td>«\\r\\n2・・・r\\n\\r» ≠ «\\n2\\n・・・n\\n\\n»</td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\n┃▁┃2┃\\n\\n┃▁┃3┃\\n\\n┃\\n┃▁┃4┃\\n\\n┃\\n\\n┃▁┃・・・┃\\n\\n┃\\n\\n┃▁┃1┃1┃\\n\\n┃\\n\\n┃\\n\\n┃\\n\\n┃\\n\\n┃\\n┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\n2\\n\\n3\\n\\n\\n4\\n\\n\\n\\n5\\n\\n\\n\\n\\n6\\n\\n\\n\\n・・・0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>32k</td>\n",
       "      <td>13.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\r┃\\n┃2┃\\r┃\\n┃\\r┃\\n┃3┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃・・・\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n・・・1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LINEBREAKS</td>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>13.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\r┃\\n┃2┃\\r┃\\n┃\\r┃\\n┃3┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃・・・\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n・・・1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TABS</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>2.3</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>1┃\\t┃2┃\\t\\t┃3┃\\t\\t\\t┃4┃\\t\\t\\t\\t┃5┃\\t\\t\\t\\t\\t┃6┃\\t\\・・・0┃\\t\\t\\t\\t┃\\t\\t\\t\\t\\t\\t┃11┃\\t\\t\\t\\t\\t\\t\\t\\t┃\\t\\t\\t</td>\n",
       "      <td>1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\t\\t7\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TABS</td>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>2.5</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\t┃2┃\\t\\t┃3┃\\t\\t\\t┃4┃\\t\\t\\t\\t┃5┃\\t\\t\\t\\t・・・t\\t┃\\t\\t\\t\\t\\t\\t┃1┃1┃\\t\\t\\t\\t\\t\\t\\t\\t┃\\t\\t\\t┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TABS</td>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>2.8</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>1┃\\t┃2┃\\t┃\\t┃3┃\\t\\t┃\\t┃4┃\\t\\t\\t┃\\t┃5┃\\t\\t\\t\\t┃\\t┃6・・・10┃\\t\\t\\t\\t\\t\\t\\t\\t\\t┃\\t┃11┃\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\t\\t7\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TABS</td>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>2.8</td>\n",
       "      <td>⚠️</td>\n",
       "      <td>digits</td>\n",
       "      <td>&lt;BOS&gt;┃1┃\\t┃2┃\\t┃\\t┃3┃\\t\\t┃\\t┃4┃\\t\\t\\t┃\\t┃5┃\\t\\t\\t\\・・・10┃\\t\\t\\t\\t\\t\\t\\t\\t\\t┃\\t┃11┃\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>&lt;BOS&gt;1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TABS</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>3.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>1┃\\t┃2┃\\t┃\\t┃3┃\\t\\t┃\\t┃4┃\\t\\t\\t┃\\t┃5┃\\t\\t\\t\\t┃\\t┃6・・・0┃\\t\\t\\t\\t\\t\\t\\t\\t\\t┃\\t┃1┃1┃\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "      <td>1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\t\\t7\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TABS</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>4.1</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\t┃▁┃2┃\\t\\t┃▁┃3┃\\t\\t\\t┃▁┃4┃\\t\\t\\t\\t┃▁┃5┃・・・\\t\\t\\t\\t┃\\t\\t┃▁┃1┃1┃\\t\\t\\t\\t┃\\t\\t\\t\\t┃\\t\\t\\t┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TABS</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>32k</td>\n",
       "      <td>7.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\t┃2┃\\t┃\\t┃3┃\\t┃\\t┃\\t┃4┃\\t┃\\t┃\\t┃\\t┃5┃\\t・・・t┃\\t┃\\t┃1┃1┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TABS</td>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>7.3</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁┃1┃\\t┃2┃\\t┃\\t┃3┃\\t┃\\t┃\\t┃4┃\\t┃\\t┃\\t┃\\t┃5┃\\t・・・t┃\\t┃\\t┃1┃1┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁anti┃rec┃ons┃titution┃nellement┃▁anti┃rec┃o・・・nellement┃▁anti┃rec┃ons┃titution┃nellement┃▁┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>GPT 4</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>ant┃ire┃constitution┃nel┃lement┃▁ant┃ire┃constitut・・・tion┃nel┃lement┃▁ant┃ire┃constitution┃nel┃lement┃▁</td>\n",
       "      <td>antireconstitutionnellement antireconstitutionnell・・・constitutionnellement antireconstitutionnellement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>Llama 3</td>\n",
       "      <td>128k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃ant┃ire┃constitution┃nel┃lement┃▁ant┃ire┃con・・・tion┃nel┃lement┃▁ant┃ire┃constitution┃nel┃lement┃▁</td>\n",
       "      <td>&lt;BOS&gt;antireconstitutionnellement antireconstitutio・・・constitutionnellement antireconstitutionnellement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>EuroLLM</td>\n",
       "      <td>128k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁anti┃recon┃stitution┃nelle┃ment┃▁anti┃recon・・・elle┃ment┃▁anti┃recon┃stitution┃nelle┃ment┃▁┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>ant┃ire┃constitution┃nel┃lement┃▁ant┃ire┃constitut・・・tion┃nel┃lement┃▁ant┃ire┃constitution┃nel┃lement┃▁</td>\n",
       "      <td>antireconstitutionnellement antireconstitutionnell・・・constitutionnellement antireconstitutionnellement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>ant┃ire┃con┃stitution┃nellement┃▁ant┃ire┃con┃stitu・・・ution┃nellement┃▁ant┃ire┃con┃stitution┃nellement┃▁</td>\n",
       "      <td>antireconstitutionnellement antireconstitutionnell・・・constitutionnellement antireconstitutionnellement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>32k</td>\n",
       "      <td>6.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁ant┃ire┃const┃itution┃nel┃lement┃▁ant┃ire┃c・・・l┃lement┃▁ant┃ire┃const┃itution┃nel┃lement┃▁┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>LONG STRING</td>\n",
       "      <td>Croissant</td>\n",
       "      <td>32k</td>\n",
       "      <td>6.0</td>\n",
       "      <td>✅</td>\n",
       "      <td></td>\n",
       "      <td>&lt;BOS&gt;┃▁anti┃rec┃ons┃titu┃tionn┃ellement┃▁anti┃rec┃・・・ellement┃▁anti┃rec┃ons┃titu┃tionn┃ellement┃▁┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;BOS&gt; antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST         tokenizer  size     fert. round-trip  \\\n",
       "0        DIGITS      Bloom  250.7k   2.0   ⚠️          \n",
       "1        DIGITS      GPT 4  100.3k   2.6   ⚠️          \n",
       "2        DIGITS    Llama 3    128k   2.6   ⚠️          \n",
       "3        DIGITS    EuroLLM    128k   3.0    ✅          \n",
       "4        DIGITS       Qwen  151.6k   3.0    ✅          \n",
       "5        DIGITS    Mistral     32k   3.2    ✅          \n",
       "6        DIGITS  Croissant     32k   3.2    ✅          \n",
       "7        DIGITS      Lucie     65k   3.2    ✅          \n",
       "8          RARE      Bloom  250.7k   1.8    ✅          \n",
       "9          RARE    Llama 3    128k   2.0    ✅          \n",
       "10         RARE      GPT 4  100.3k   2.2    ✅          \n",
       "11         RARE       Qwen  151.6k   2.2    ✅          \n",
       "12         RARE    EuroLLM    128k   2.3    ✅          \n",
       "13         RARE    Mistral     32k   2.5    ✅          \n",
       "14         RARE  Croissant     32k   2.5    ❌          \n",
       "15         RARE      Lucie     65k   3.3    ✅          \n",
       "16         MATH  Croissant     32k   8.0    ❌          \n",
       "17         MATH    Llama 3    128k  10.0    ✅          \n",
       "18         MATH       Qwen  151.6k  10.0    ✅          \n",
       "19         MATH      Bloom  250.7k  10.0    ✅          \n",
       "20         MATH    Mistral     32k  11.0    ✅          \n",
       "21         MATH      Lucie     65k  11.0    ✅          \n",
       "22         MATH      GPT 4  100.3k  11.0    ✅          \n",
       "23         MATH    EuroLLM    128k  12.0    ✅          \n",
       "24       SPACES      Bloom  250.7k   2.2   ⚠️          \n",
       "25       SPACES      Lucie     65k   2.5    ❌          \n",
       "26       SPACES    Llama 3    128k   2.9   ⚠️          \n",
       "27       SPACES      GPT 4  100.3k   3.0   ⚠️          \n",
       "28       SPACES       Qwen  151.6k   3.2    ✅          \n",
       "29       SPACES    Mistral     32k   4.7    ✅          \n",
       "30       SPACES  Croissant     32k   7.2    ❌          \n",
       "31       SPACES    EuroLLM    128k   7.7    ✅          \n",
       "32   LINEBREAKS      GPT 4  100.3k   2.9   ⚠️          \n",
       "33   LINEBREAKS    Llama 3    128k   2.9   ⚠️          \n",
       "34   LINEBREAKS       Qwen  151.6k   3.1    ✅          \n",
       "35   LINEBREAKS      Bloom  250.7k   3.8   ⚠️          \n",
       "36   LINEBREAKS  Croissant     32k   4.5    ✅          \n",
       "37   LINEBREAKS      Lucie     65k   5.5    ❌          \n",
       "38   LINEBREAKS    Mistral     32k  13.3    ✅          \n",
       "39   LINEBREAKS    EuroLLM    128k  13.3    ✅          \n",
       "40         TABS      Bloom  250.7k   2.3   ⚠️          \n",
       "41         TABS  Croissant     32k   2.5    ✅          \n",
       "42         TABS      GPT 4  100.3k   2.8   ⚠️          \n",
       "43         TABS    Llama 3    128k   2.8   ⚠️          \n",
       "44         TABS       Qwen  151.6k   3.0    ✅          \n",
       "45         TABS      Lucie     65k   4.1    ✅          \n",
       "46         TABS    Mistral     32k   7.3    ✅          \n",
       "47         TABS    EuroLLM    128k   7.3    ✅          \n",
       "48  LONG STRING      Lucie     65k   5.0    ✅          \n",
       "49  LONG STRING      GPT 4  100.3k   5.0    ✅          \n",
       "50  LONG STRING    Llama 3    128k   5.0    ✅          \n",
       "51  LONG STRING    EuroLLM    128k   5.0    ✅          \n",
       "52  LONG STRING       Qwen  151.6k   5.0    ✅          \n",
       "53  LONG STRING      Bloom  250.7k   5.0    ✅          \n",
       "54  LONG STRING    Mistral     32k   6.0    ✅          \n",
       "55  LONG STRING  Croissant     32k   6.0    ✅          \n",
       "\n",
       "   comment                             \\\n",
       "0                              digits   \n",
       "1                              digits   \n",
       "2                              digits   \n",
       "3                                       \n",
       "4                                       \n",
       "5                                       \n",
       "6                                       \n",
       "7                                       \n",
       "8                                       \n",
       "9                                       \n",
       "10                                      \n",
       "11                                      \n",
       "12                                      \n",
       "13                                      \n",
       "14  «½▁smi・・・na▁あ゙» ≠ «1⁄2▁s・・・ana▁あ»   \n",
       "15                                      \n",
       "16                         «²÷» ≠ «2»   \n",
       "17                                      \n",
       "18                                      \n",
       "19                                      \n",
       "20                                      \n",
       "21                                      \n",
       "22                                      \n",
       "23                                      \n",
       "24                             digits   \n",
       "25  «⍽2▁▁2・・・⍽⍽⍽⍽⍽» ≠ «▁2▁▁2・・・▁▁▁▁▁»   \n",
       "26                             digits   \n",
       "27                             digits   \n",
       "28                                      \n",
       "29                                      \n",
       "30  «⍽2▁▁2・・・⍽⍽⍽⍽⍽» ≠ «▁2▁▁2・・・▁▁▁▁▁»   \n",
       "31                                      \n",
       "32                             digits   \n",
       "33                             digits   \n",
       "34                                      \n",
       "35                             digits   \n",
       "36                                      \n",
       "37  «\\r\\n2・・・r\\n\\r» ≠ «\\n2\\n・・・n\\n\\n»   \n",
       "38                                      \n",
       "39                                      \n",
       "40                             digits   \n",
       "41                                      \n",
       "42                             digits   \n",
       "43                             digits   \n",
       "44                                      \n",
       "45                                      \n",
       "46                                      \n",
       "47                                      \n",
       "48                                      \n",
       "49                                      \n",
       "50                                      \n",
       "51                                      \n",
       "52                                      \n",
       "53                                      \n",
       "54                                      \n",
       "55                                      \n",
       "\n",
       "   encoded tokens                                                                                            \\\n",
       "0                                                                        wav┃2┃vec┃▁pour┃▁1┃.┃5┃€┃▁en┃▁2024   \n",
       "1                                                                     wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃202┃4   \n",
       "2                                                               <BOS>┃wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃202┃4   \n",
       "3                                                      <BOS>┃▁wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃<EOS>   \n",
       "4                                                                   wav┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4   \n",
       "5                                                     <BOS>┃▁w┃av┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃<EOS>   \n",
       "6                                                     <BOS>┃▁w┃av┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃<EOS>   \n",
       "7                                                     <BOS>┃▁w┃av┃2┃vec┃▁pour┃▁┃1┃.┃5┃€┃▁en┃▁┃2┃0┃2┃4┃<EOS>   \n",
       "8                                                               fraction┃▁½┃▁sm┃iley┃▁�┃�┃▁kat┃akana┃▁あ┃�┃�   \n",
       "9                                                         <BOS>┃fraction┃▁┃½┃▁smile┃y┃▁😀┃▁kata┃k┃ana┃▁あ┃�┃�   \n",
       "10                                                             fraction┃▁┃½┃▁smile┃y┃▁😀┃▁kata┃k┃ana┃▁┃あ┃�┃�   \n",
       "11                                                             fraction┃▁┃½┃▁smile┃y┃▁😀┃▁kata┃k┃ana┃▁┃あ┃�┃�   \n",
       "12                                             <BOS>┃▁fraction┃▁┃�┃�┃▁sm┃iley┃▁😀┃▁kat┃ak┃ana┃▁あ┃�┃�┃�┃<EOS>   \n",
       "13                                             <BOS>┃▁fraction┃▁┃½┃▁smile┃y┃▁┃😀┃▁kat┃ak┃ana┃▁┃あ┃�┃�┃�┃<EOS>   \n",
       "14                                              <BOS>┃▁fraction┃▁┃1┃⁄┃2┃▁smile┃y┃▁┃😀┃▁k┃ata┃k┃ana┃▁┃あ┃<EOS>   \n",
       "15                                   <BOS>┃▁fraction┃▁┃½┃▁sm┃iley┃▁┃�┃�┃�┃�┃▁k┃atak┃ana┃▁┃�┃�┃�┃�┃�┃�┃<EOS>   \n",
       "16                                                                          <BOS>┃▁a.┃(b┃+┃c)┃2┃e┃×┃f┃<EOS>   \n",
       "17                                                                              <BOS>┃a┃.(┃b┃+c┃)┃²┃÷┃e┃×┃f   \n",
       "18                                                                                    a┃.(┃b┃+c┃)┃²┃÷┃e┃×┃f   \n",
       "19                                                                                    a┃.(┃b┃+c┃)┃²┃÷┃e┃×┃f   \n",
       "20                                                                      <BOS>┃▁a┃.(┃b┃+┃c┃)┃²┃÷┃e┃×┃f┃<EOS>   \n",
       "21                                                                     <BOS>┃▁a┃.(┃▁b┃+┃c┃)┃²┃÷┃e┃×┃f┃<EOS>   \n",
       "22                                                                                  a┃.(┃b┃+c┃)┃²┃�┃�┃e┃×┃f   \n",
       "23                                                                    <BOS>┃▁a┃.(┃b┃+┃c┃)┃�┃�┃÷┃e┃×┃f┃<EOS>   \n",
       "24  1┃▁1┃⍽┃2┃▁┃▁2┃⍽⍽┃3┃▁▁┃▁3┃⍽⍽⍽┃4┃▁▁▁┃▁4┃⍽⍽⍽⍽┃5┃▁▁▁▁┃・・・▁▁▁┃▁10┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽┃11┃▁▁▁▁▁▁▁▁▁▁┃▁11┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽⍽   \n",
       "25  <BOS>┃▁┃1┃▁┃1┃▁┃2┃▁┃2┃▁┃3┃▁┃3┃▁┃4┃▁┃4┃▁┃5┃▁┃5┃▁┃6┃・・・┃9┃▁┃▁┃9┃▁┃▁┃1┃0┃▁┃▁┃1┃0┃▁┃▁┃1┃1┃▁┃▁┃1┃1┃▁┃▁┃<EOS>   \n",
       "26  <BOS>┃1┃▁┃1┃⍽┃2┃▁┃▁┃2┃⍽┃⍽┃3┃▁▁┃▁┃3┃⍽⍽┃⍽┃4┃▁▁▁┃▁┃4┃・・・▁▁┃▁┃10┃⍽⍽⍽⍽⍽⍽⍽⍽⍽┃⍽┃11┃▁▁▁▁▁▁▁▁▁▁┃▁┃11┃⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽   \n",
       "27  1┃▁┃1┃⍽┃2┃▁┃▁┃2┃⍽┃⍽┃3┃▁▁┃▁┃3┃⍽⍽┃⍽┃4┃▁▁▁┃▁┃4┃⍽⍽⍽┃⍽┃・・・┃▁┃10┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽┃⍽┃11┃▁▁▁▁▁▁▁▁▁▁┃▁┃11┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽⍽   \n",
       "28  1┃▁┃1┃⍽┃2┃▁┃▁┃2┃⍽┃⍽┃3┃▁▁┃▁┃3┃⍽⍽┃⍽┃4┃▁▁▁┃▁┃4┃⍽⍽⍽┃⍽┃・・・1┃0┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽┃⍽┃1┃1┃▁▁▁▁▁▁▁▁▁▁┃▁┃1┃1┃⍽⍽⍽⍽⍽⍽⍽⍽┃⍽⍽⍽   \n",
       "29  <BOS>┃▁┃1┃▁┃1┃⍽┃2┃▁┃2┃⍽┃⍽┃3┃▁▁┃3┃⍽┃⍽┃⍽┃4┃▁▁▁┃4┃⍽┃⍽・・・⍽┃⍽┃1┃1┃▁▁▁▁▁▁▁▁▁▁┃1┃1┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃⍽┃<EOS>   \n",
       "30  <BOS>┃▁┃1┃▁┃1┃▁┃2┃▁┃▁┃2┃▁┃▁┃3┃▁┃▁┃▁┃3┃▁┃▁┃▁┃4┃▁┃▁┃・・・┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃1┃1┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃▁┃<EOS>   \n",
       "31  <BOS>┃▁┃1┃▁┃1┃�┃�┃2┃▁┃2┃�┃�┃�┃�┃3┃▁▁┃3┃�┃�┃�┃�┃�┃�・・・┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃�┃<EOS>   \n",
       "32  1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n\\r\\n\\r\\・・・┃11┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n   \n",
       "33  <BOS>┃1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n\\・・・┃11┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n   \n",
       "34  1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n\\r\\n\\r\\・・・1┃1┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n   \n",
       "35  1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n\\r\\n┃4┃\\r\\n\\r\\n┃\\r\\n\\r・・・1┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n\\r\\n   \n",
       "36  <BOS>┃▁┃1┃\\r\\n┃2┃\\r\\n\\r\\n┃3┃\\r\\n\\r\\n┃\\r\\n┃4┃\\r\\n\\r・・・r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n\\r\\n┃\\r\\n┃<EOS>   \n",
       "37  <BOS>┃▁┃1┃\\n┃▁┃2┃\\n\\n┃▁┃3┃\\n\\n┃\\n┃▁┃4┃\\n\\n┃\\n\\n┃▁┃・・・┃\\n\\n┃\\n\\n┃▁┃1┃1┃\\n\\n┃\\n\\n┃\\n\\n┃\\n\\n┃\\n\\n┃\\n┃<EOS>   \n",
       "38  <BOS>┃▁┃1┃\\r┃\\n┃2┃\\r┃\\n┃\\r┃\\n┃3┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃・・・\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃<EOS>   \n",
       "39  <BOS>┃▁┃1┃\\r┃\\n┃2┃\\r┃\\n┃\\r┃\\n┃3┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃・・・\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃\\r┃\\n┃<EOS>   \n",
       "40  1┃\\t┃2┃\\t\\t┃3┃\\t\\t\\t┃4┃\\t\\t\\t\\t┃5┃\\t\\t\\t\\t\\t┃6┃\\t\\・・・0┃\\t\\t\\t\\t┃\\t\\t\\t\\t\\t\\t┃11┃\\t\\t\\t\\t\\t\\t\\t\\t┃\\t\\t\\t   \n",
       "41  <BOS>┃▁┃1┃\\t┃2┃\\t\\t┃3┃\\t\\t\\t┃4┃\\t\\t\\t\\t┃5┃\\t\\t\\t\\t・・・t\\t┃\\t\\t\\t\\t\\t\\t┃1┃1┃\\t\\t\\t\\t\\t\\t\\t\\t┃\\t\\t\\t┃<EOS>   \n",
       "42  1┃\\t┃2┃\\t┃\\t┃3┃\\t\\t┃\\t┃4┃\\t\\t\\t┃\\t┃5┃\\t\\t\\t\\t┃\\t┃6・・・10┃\\t\\t\\t\\t\\t\\t\\t\\t\\t┃\\t┃11┃\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "43  <BOS>┃1┃\\t┃2┃\\t┃\\t┃3┃\\t\\t┃\\t┃4┃\\t\\t\\t┃\\t┃5┃\\t\\t\\t\\・・・10┃\\t\\t\\t\\t\\t\\t\\t\\t\\t┃\\t┃11┃\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "44  1┃\\t┃2┃\\t┃\\t┃3┃\\t\\t┃\\t┃4┃\\t\\t\\t┃\\t┃5┃\\t\\t\\t\\t┃\\t┃6・・・0┃\\t\\t\\t\\t\\t\\t\\t\\t\\t┃\\t┃1┃1┃\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   \n",
       "45  <BOS>┃▁┃1┃\\t┃▁┃2┃\\t\\t┃▁┃3┃\\t\\t\\t┃▁┃4┃\\t\\t\\t\\t┃▁┃5┃・・・\\t\\t\\t\\t┃\\t\\t┃▁┃1┃1┃\\t\\t\\t\\t┃\\t\\t\\t\\t┃\\t\\t\\t┃<EOS>   \n",
       "46  <BOS>┃▁┃1┃\\t┃2┃\\t┃\\t┃3┃\\t┃\\t┃\\t┃4┃\\t┃\\t┃\\t┃\\t┃5┃\\t・・・t┃\\t┃\\t┃1┃1┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃<EOS>   \n",
       "47  <BOS>┃▁┃1┃\\t┃2┃\\t┃\\t┃3┃\\t┃\\t┃\\t┃4┃\\t┃\\t┃\\t┃\\t┃5┃\\t・・・t┃\\t┃\\t┃1┃1┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃\\t┃<EOS>   \n",
       "48  <BOS>┃▁anti┃rec┃ons┃titution┃nellement┃▁anti┃rec┃o・・・nellement┃▁anti┃rec┃ons┃titution┃nellement┃▁┃<EOS>   \n",
       "49  ant┃ire┃constitution┃nel┃lement┃▁ant┃ire┃constitut・・・tion┃nel┃lement┃▁ant┃ire┃constitution┃nel┃lement┃▁   \n",
       "50  <BOS>┃ant┃ire┃constitution┃nel┃lement┃▁ant┃ire┃con・・・tion┃nel┃lement┃▁ant┃ire┃constitution┃nel┃lement┃▁   \n",
       "51  <BOS>┃▁anti┃recon┃stitution┃nelle┃ment┃▁anti┃recon・・・elle┃ment┃▁anti┃recon┃stitution┃nelle┃ment┃▁┃<EOS>   \n",
       "52  ant┃ire┃constitution┃nel┃lement┃▁ant┃ire┃constitut・・・tion┃nel┃lement┃▁ant┃ire┃constitution┃nel┃lement┃▁   \n",
       "53  ant┃ire┃con┃stitution┃nellement┃▁ant┃ire┃con┃stitu・・・ution┃nellement┃▁ant┃ire┃con┃stitution┃nellement┃▁   \n",
       "54  <BOS>┃▁ant┃ire┃const┃itution┃nel┃lement┃▁ant┃ire┃c・・・l┃lement┃▁ant┃ire┃const┃itution┃nel┃lement┃▁┃<EOS>   \n",
       "55  <BOS>┃▁anti┃rec┃ons┃titu┃tionn┃ellement┃▁anti┃rec┃・・・ellement┃▁anti┃rec┃ons┃titu┃tionn┃ellement┃▁┃<EOS>   \n",
       "\n",
       "   decoded text                                                                                              \n",
       "0                                                                                 wav2vec pour 1.5€ en 2024  \n",
       "1                                                                                 wav2vec pour 1.5€ en 2024  \n",
       "2                                                                            <BOS>wav2vec pour 1.5€ en 2024  \n",
       "3                                                                      <BOS> wav2vec pour 1.5€ en 2024<EOS>  \n",
       "4                                                                                 wav2vec pour 1.5€ en 2024  \n",
       "5                                                                      <BOS> wav2vec pour 1.5€ en 2024<EOS>  \n",
       "6                                                                      <BOS> wav2vec pour 1.5€ en 2024<EOS>  \n",
       "7                                                                      <BOS> wav2vec pour 1.5€ en 2024<EOS>  \n",
       "8                                                                           fraction ½ smiley 😀 katakana あ゙  \n",
       "9                                                                      <BOS>fraction ½ smiley 😀 katakana あ゙  \n",
       "10                                                                          fraction ½ smiley 😀 katakana あ゙  \n",
       "11                                                                          fraction ½ smiley 😀 katakana あ゙  \n",
       "12                                                               <BOS> fraction ½ smiley 😀 katakana あ゙<EOS>  \n",
       "13                                                               <BOS> fraction ½ smiley 😀 katakana あ゙<EOS>  \n",
       "14                                                              <BOS> fraction 1⁄2 smiley 😀 katakana あ<EOS>  \n",
       "15                                                               <BOS> fraction ½ smiley 😀 katakana あ゙<EOS>  \n",
       "16                                                                                   <BOS> a.(b+c)2e×f<EOS>  \n",
       "17                                                                                        <BOS>a.(b+c)²÷e×f  \n",
       "18                                                                                             a.(b+c)²÷e×f  \n",
       "19                                                                                             a.(b+c)²÷e×f  \n",
       "20                                                                                  <BOS> a.(b+c)²÷e×f<EOS>  \n",
       "21                                                                                  <BOS> a.(b+c)²÷e×f<EOS>  \n",
       "22                                                                                             a.(b+c)²÷e×f  \n",
       "23                                                                                  <BOS> a.(b+c)²÷e×f<EOS>  \n",
       "24  1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6      6⍽⍽・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽  \n",
       "25  <BOS> 1 1 2  2  3   3   4    4    5     5     6   ・・・       10          11           11           <EOS>  \n",
       "26  <BOS>1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6    ・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽  \n",
       "27  1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6      6⍽⍽・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽  \n",
       "28  1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6      6⍽⍽・・・10          10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽  \n",
       "29  <BOS> 1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6   ・・・       10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽<EOS>  \n",
       "30  <BOS> 1 1 2  2  3   3   4    4    5     5     6   ・・・       10          11           11           <EOS>  \n",
       "31  <BOS> 1 1⍽2  2⍽⍽3   3⍽⍽⍽4    4⍽⍽⍽⍽5     5⍽⍽⍽⍽⍽6   ・・・       10⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽11           11⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽⍽<EOS>  \n",
       "32  1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5\\r\\n\\・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  \n",
       "33  <BOS>1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  \n",
       "34  1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5\\r\\n\\・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  \n",
       "35  1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n5\\r\\n\\・・・\\r\\n11\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  \n",
       "36  <BOS> 1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n・・・1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n<EOS>  \n",
       "37  <BOS> 1\\n2\\n\\n3\\n\\n\\n4\\n\\n\\n\\n5\\n\\n\\n\\n\\n6\\n\\n\\n\\n・・・0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n<EOS>  \n",
       "38  <BOS> 1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n・・・1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n<EOS>  \n",
       "39  <BOS> 1\\r\\n2\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n・・・1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n<EOS>  \n",
       "40  1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\t\\t7\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \n",
       "41  <BOS> 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<EOS>  \n",
       "42  1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\t\\t7\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \n",
       "43  <BOS>1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \n",
       "44  1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t\\t\\t7\\・・・\\t\\t10\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \n",
       "45  <BOS> 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<EOS>  \n",
       "46  <BOS> 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<EOS>  \n",
       "47  <BOS> 1\\t2\\t\\t3\\t\\t\\t4\\t\\t\\t\\t5\\t\\t\\t\\t\\t6\\t\\t\\t\\t・・・0\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t11\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<EOS>  \n",
       "48  <BOS> antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement <EOS>  \n",
       "49  antireconstitutionnellement antireconstitutionnell・・・constitutionnellement antireconstitutionnellement   \n",
       "50  <BOS>antireconstitutionnellement antireconstitutio・・・constitutionnellement antireconstitutionnellement   \n",
       "51  <BOS> antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement <EOS>  \n",
       "52  antireconstitutionnellement antireconstitutionnell・・・constitutionnellement antireconstitutionnellement   \n",
       "53  antireconstitutionnellement antireconstitutionnell・・・constitutionnellement antireconstitutionnellement   \n",
       "54  <BOS> antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement <EOS>  \n",
       "55  <BOS> antireconstitutionnellement antireconstituti・・・itutionnellement antireconstitutionnellement <EOS>  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokenizers_batch(\n",
    "    {\n",
    "        \"DIGITS\":\n",
    "            \"wav2vec pour 1.5€ en 2024\",\n",
    "        \"RARE\":\n",
    "            \"fraction ½ smiley 😀 katakana あ゙\",\n",
    "        \"MATH\":\n",
    "            \"a.(b+c)²÷e×f\",\n",
    "        \"SPACES\":\n",
    "            \"\".join([f\"{i}{' '*i}{i}{' '*i}\" for i in range(1, 12)]),\n",
    "        \"LINEBREAKS\":\n",
    "            \"\".join([f\"{i}\" + (\"\\r\\n\"*i) for i in range(1, 12)]),\n",
    "        \"TABS\":\n",
    "            \"\".join([f\"{i}\" + (\"\\t\"*i) for i in range(1, 12)]),\n",
    "        \"LONG STRING\":\n",
    "            \"antireconstitutionnellement \" * 32000,\n",
    "    },\n",
    "    [\"GPT 4\", \"Mistral\", \"Llama 3\", \"Qwen\", \"Bloom\", \"Croissant\", \"EuroLLM\", \"Lucie\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"benchmark\">🧪🏆 Benchmark fertility</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x1296 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear_cache()\n",
    "\n",
    "benchmark_fertility(\n",
    "    [\n",
    "        (\"wikimedia/wikipedia\", \"20231101.\" + lan)\n",
    "        for lan in [\"en\", \"fr\", \"es\", \"it\", \"de\"]\n",
    "    ],\n",
    "    [\"GPT 4\", \"Gemma\", \"Phi 3\", \"Mistral\", \"Llama 3\", \"Qwen\", \"Bloom\", \"Croissant\", \"EuroLLM\", \"Lucie\", \"C4\", \"Olmo 2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"templates\">🔢💬 Chat templates</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since LLM are often used for chatbot applications,\n",
    "models are often trained on dialogues, with a particular pattern to indicate speech turns, involving special tokens/tags. <br>\n",
    "This templating can be as a pre-processing step of the model, and it is usually stored with the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👤 Mistral:\n",
      "------------\n",
      "<s>[INST] Hello robot[/INST] Hello human! How can I help?</s>[INST] Make me a coffee[/INST]\n",
      "💬 <BOS>┃[INST] ┃《…》\n",
      "💬 [/INST] ┃《…》\n",
      "💬 <EOS> \n",
      "\n",
      "👤 Zephyr:\n",
      "-----------\n",
      "<|user|>\n",
      "Hello robot</s>\n",
      "<|assistant|>\n",
      "Hello human! How can I help?</s>\n",
      "<|user|>\n",
      "Make me a coffee</s>\n",
      "\n",
      "💬 ▁<┃|┃user┃|┃>┃\\n┃. ┃《…》\n",
      "💬 <EOS>┃▁┃\\n┃<┃|┃ass┃istant┃|┃>┃\\n┃. ┃《…》\n",
      "💬 <EOS>┃▁┃\\n \n",
      "\n",
      "👤 Olmo 2:\n",
      "-----------\n",
      "<|endoftext|><|user|>\n",
      "Hello robot\n",
      "<|assistant|>\n",
      "Hello human! How can I help?<|endoftext|>\n",
      "<|user|>\n",
      "Make me a coffee\n",
      "\n",
      "💬 <EOS>┃<┃|┃user┃|┃>┃\\n ┃《…》\n",
      "💬 \\n┃<┃|┃assistant┃|┃>┃\\n ┃《…》\n",
      "💬 <EOS> \n",
      "\n",
      "👤 Llama 3:\n",
      "------------\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello robot<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Hello human! How can I help?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Make me a coffee<|eot_id|>\n",
      "💬 <BOS>┃<start_header_id>┃user┃<end_header_id>┃\\n\\n ┃《…》\n",
      "💬 <eot_id>┃<start_header_id>┃assistant┃<end_header_id>┃\\n\\n ┃《…》\n",
      "💬 <eot_id> \n",
      "\n",
      "👤 OpenLLM-France/Lucie-7B-Baby-Instruct:\n",
      "------------------------------------------\n",
      "<s>### User:\n",
      "Hello robot\n",
      "\n",
      "### Assistant:\n",
      "Hello human! How can I help?</s>\n",
      "\n",
      "### User:\n",
      "Make me a coffee\n",
      "\n",
      "\n",
      "💬 <BOS>┃▁###┃▁User┃:┃\\n┃. ┃《…》\n",
      "💬 \\n\\n┃###┃▁Assistant┃:┃\\n┃. ┃《…》\n",
      "💬 <EOS>┃▁┃\\n\\n \n"
     ]
    }
   ],
   "source": [
    "show_templates(\n",
    "    [\"Mistral\", \"Zephyr\", \"Olmo 2\", \"Llama 3\", \"OpenLLM-France/Lucie-7B-Baby-Instruct\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience feedback:**\n",
    "* It seems better to have tags to indicate both the start AND the end of each \"speech turn\", so that the model can learn more easily to stop generating text.\n",
    "* ⚠️ Using the wrong template (mismatch between training and inference) can lead the LLM\n",
    "   * to generate text that is not coherent with the context,\n",
    "   * to stop answering prematurely,\n",
    "   * to generate special stags from the pattern.\n",
    "\n",
    "Templates can come in different formats, and for those previous reasons it is important to provide/use a good template setup. <br>\n",
    "* With `tokenizers`/`transformers`, the template is stored in a JSON file [`tokenizer_config.json`](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/blob/main/tokenizer_config.json):\n",
    "```json\t\n",
    "{\n",
    "  \"chat_template\": \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\",\n",
    "}\n",
    "```\n",
    "* With [ollama](https://ollama.com/), parameter `TEMPLATE` in the [`Modelfile`](https://github.com/ollama/ollama/blob/main/docs/modelfile.md#format) is in GO format:\n",
    "```go\n",
    "TEMPLATE \"\"\"{{ if .System }}<|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{{ .System }}<|eot_id|>{{ end }}{{ if .Prompt }}<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{{ .Prompt }}<|eot_id|>{{ end }}<|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{{ .Response }}<|eot_id|>\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"padding\">🔢✂️ Padding and Truncation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padded is needed when processing <u>batch of variable-length sequences</u>.\n",
    "<br> When training a LLM, with a fixed context length, sequences of tokens are either packed (for efficiency) or padded/truncated to the context length (and losses have to be masked accordingly).\n",
    "\n",
    "Padding can be\n",
    "* added on the left or on the right (if on the left, be careful with auto-regressive LLMs, to use the right causal mask)\n",
    "* done with a value that is a special dedicated token `<pad>`, or simply the `<EOS>` token (end of sequence).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 Qwen does pad on the right\n",
      "🧮 Lucie does pad on the left\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>size</th>\n",
       "      <th>round-trip</th>\n",
       "      <th>encoded tokens</th>\n",
       "      <th>decoded text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olmo 2</td>\n",
       "      <td>100.3k</td>\n",
       "      <td>✅</td>\n",
       "      <td>Bonjour┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;</td>\n",
       "      <td>Bonjour&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>151.6k</td>\n",
       "      <td>✅</td>\n",
       "      <td>Bonjour┃&lt;EOS&gt;┃&lt;EOS&gt;┃&lt;EOS&gt;┃&lt;EOS&gt;┃&lt;EOS&gt;┃&lt;EOS&gt;</td>\n",
       "      <td>Bonjour&lt;EOS&gt;&lt;EOS&gt;&lt;EOS&gt;&lt;EOS&gt;&lt;EOS&gt;&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zephyr</td>\n",
       "      <td>32k</td>\n",
       "      <td>✅</td>\n",
       "      <td>&lt;EOS&gt;┃&lt;EOS&gt;┃&lt;EOS&gt;┃&lt;BOS&gt;┃▁Bon┃jour┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;EOS&gt;&lt;EOS&gt;&lt;EOS&gt;&lt;BOS&gt; Bonjour&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bloom</td>\n",
       "      <td>250.7k</td>\n",
       "      <td>✅</td>\n",
       "      <td>&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃Bonjour</td>\n",
       "      <td>&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;Bonjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C4</td>\n",
       "      <td>255k</td>\n",
       "      <td>✅</td>\n",
       "      <td>&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;BOS&gt;┃Bon┃jour┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;BOS&gt;Bonjour&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lucie</td>\n",
       "      <td>65k</td>\n",
       "      <td>✅</td>\n",
       "      <td>&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;pad&gt;┃&lt;BOS&gt;┃▁Bonjour┃&lt;EOS&gt;</td>\n",
       "      <td>&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;BOS&gt; Bonjour&lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenizer size    round-trip encoded tokens                                 \\\n",
       "0  Olmo 2    100.3k  ✅           Bonjour┃<pad>┃<pad>┃<pad>┃<pad>┃<pad>┃<pad>   \n",
       "1    Qwen    151.6k  ✅           Bonjour┃<EOS>┃<EOS>┃<EOS>┃<EOS>┃<EOS>┃<EOS>   \n",
       "2  Zephyr       32k  ✅               <EOS>┃<EOS>┃<EOS>┃<BOS>┃▁Bon┃jour┃<EOS>   \n",
       "3   Bloom    250.7k  ✅           <pad>┃<pad>┃<pad>┃<pad>┃<pad>┃<pad>┃Bonjour   \n",
       "4      C4      255k  ✅                <pad>┃<pad>┃<pad>┃<BOS>┃Bon┃jour┃<EOS>   \n",
       "5   Lucie       65k  ✅          <pad>┃<pad>┃<pad>┃<pad>┃<BOS>┃▁Bonjour┃<EOS>   \n",
       "\n",
       "  decoded text                             \n",
       "0   Bonjour<pad><pad><pad><pad><pad><pad>  \n",
       "1   Bonjour<EOS><EOS><EOS><EOS><EOS><EOS>  \n",
       "2       <EOS><EOS><EOS><BOS> Bonjour<EOS>  \n",
       "3   <pad><pad><pad><pad><pad><pad>Bonjour  \n",
       "4        <pad><pad><pad><BOS>Bonjour<EOS>  \n",
       "5  <pad><pad><pad><pad><BOS> Bonjour<EOS>  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in [\n",
    "    \"Qwen\",\n",
    "    \"Lucie\"\n",
    "]:\n",
    "    tokenizer = load_tokenizer_with_cache(name)\n",
    "    print(f\"🧮 {name} does pad on the {tokenizer.padding_side}\")\n",
    "\n",
    "\n",
    "test_tokenizers(\n",
    "    \"Bonjour\",\n",
    "    [\"Olmo 2\", \"Qwen\", \"Zephyr\", \"Bloom\", \"C4\", \"Lucie\"],\n",
    "    display_fertility=False,\n",
    "    # 👇 Options for padding (with tokenizers lib)\n",
    "    padding='max_length', truncation=True, max_length=7,\n",
    ")\n",
    "\n",
    "# Note: with \"Llama 3\", \"Llama 2\", \"Falcon\", \"EuroLLM\", ... padding should be set explicitly\n",
    "#   ValueError: Asking to pad but the tokenizer does not have a padding token.\n",
    "#   Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"training\">🤖🧠 Train a new tokenizer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to collect a dataset of text data to train a new tokenizer.\n",
    "<br>*How much?*\n",
    "[Lucie tokenizer](https://huggingface.co/OpenLLM-France/Lucie-7B) was done on 2.78B words of text in French, English, German, Spanish and Italian [(see details here)](https://github.com/OpenLLM-France/Lucie-Training/blob/master/chronicles/tokenization/stats_train_tokenizer.csv).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a super simple example, where you can see how tokens are chosen, in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>▁ton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>▁tonton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>▁ton▁tonton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>▁tond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>▁s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>,▁ton▁tonton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a▁tond</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token        \n",
       "1              ▁\n",
       "2              ,\n",
       "3              .\n",
       "4              a\n",
       "5              d\n",
       "6              e\n",
       "7              i\n",
       "8              n\n",
       "9              o\n",
       "10             r\n",
       "11             s\n",
       "12             t\n",
       "13             u\n",
       "14            on\n",
       "15           ton\n",
       "16          ▁ton\n",
       "17       ▁tonton\n",
       "18   ▁ton▁tonton\n",
       "19         ▁tond\n",
       "20            ▁s\n",
       "21  ,▁ton▁tonton\n",
       "22        a▁tond"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tokenizers\n",
    "\n",
    "text = \"si ton tonton tond ton tonton, ton tonton sera tondu.\"\n",
    "\n",
    "num_unique_chars = len(set(text)) # 13 unique characters in the text\n",
    "\n",
    "sorted_tokens = []\n",
    "for vocab_size in range(num_unique_chars, num_unique_chars+10):\n",
    "    tokenizer = tokenizers.Tokenizer(\n",
    "        tokenizers.models.BPE(\n",
    "            dropout=None,\n",
    "            unk_token=\"<unk>\",\n",
    "            fuse_unk=True,\n",
    "            byte_fallback=True,\n",
    "        )\n",
    "    )\n",
    "    def text_iterator():\n",
    "        yield text\n",
    "    tokenizer.train_from_iterator(\n",
    "        text_iterator(),\n",
    "        trainer=tokenizers.trainers.BpeTrainer(\n",
    "            vocab_size=vocab_size,\n",
    "            show_progress=False,\n",
    "        )\n",
    "    )\n",
    "    for token in get_vocabulary(tokenizer):\n",
    "        if token not in sorted_tokens:\n",
    "            sorted_tokens.append(token)\n",
    "\n",
    "pd.DataFrame(sorted_tokens, index = range(1, len(sorted_tokens)+1), columns=[\"Token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>nchars</th>\n",
       "      <th>start</th>\n",
       "      <th>#tokens</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#…</td>\n",
       "      <td>12</td>\n",
       "      <td>[,, ., a, d, e, i, n, o, r, s, t, u]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>#…</td>\n",
       "      <td>1</td>\n",
       "      <td>[on]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>#…</td>\n",
       "      <td>1</td>\n",
       "      <td>[ton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁ton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁tond]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>#…</td>\n",
       "      <td>1</td>\n",
       "      <td>[a▁tond]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁tonton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>▶</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁ton▁tonton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>#…</td>\n",
       "      <td>1</td>\n",
       "      <td>[,▁ton▁tonton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td></td>\n",
       "      <td>22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nchars start  #tokens tokens                               \n",
       "0       0   ▶     1                                        [▁]\n",
       "1       1  #…    12       [,, ., a, d, e, i, n, o, r, s, t, u]\n",
       "2       1   ▶     1                                       [▁s]\n",
       "3       2  #…     1                                       [on]\n",
       "4       3  #…     1                                      [ton]\n",
       "5       3   ▶     1                                     [▁ton]\n",
       "6       4   ▶     1                                    [▁tond]\n",
       "7       6  #…     1                                   [a▁tond]\n",
       "8       6   ▶     1                                  [▁tonton]\n",
       "9      10   ▶     1                              [▁ton▁tonton]\n",
       "10     12  #…     1                             [,▁ton▁tonton]\n",
       "11  TOTAL        22                                           "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocabulary(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is impossible to have a token with 3 characters (\"ton\") without having some sub-tokens with less characters to generate it (\"t\" and \"on\" here).\n",
    "\n",
    "BPE works like this. The order of the tokens in the vocabulary has an influence (it is a priority), and tokens are glued in a greedy fashion to compose new tokens.\n",
    "<br>The goal being to minimize fertility for the given vocabulary size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some scripts to train a tokenizer:\n",
    "* with `tiktoken` library\n",
    "  * [openai does not plan to open the code to train...](https://github.com/openai/tiktoken/issues/25)\n",
    "* with `sentencepiece`\n",
    "  * ... TODO ...\n",
    "* with `tokenizers` library:\n",
    "  * [`tokenizer_train.py`@OpenLLM-France/Lucie-Training](https://github.com/OpenLLM-France/Lucie-Training/blob/master/tokenization/tokenizer_train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, when designing/training a new tokenizer, the devil is in the details.\n",
    "\n",
    "Look at all options in the script [`tokenizer_train.py`@OpenLLM-France/Lucie-Training](https://github.com/OpenLLM-France/Lucie-Training/blob/master/tokenization/tokenizer_train.py):\n",
    "```bash\n",
    "python3 tokenizer_train.py -h\n",
    "```\n",
    "```plaintext\n",
    "usage: tokenizer_train.py [-h] [--vocab_size VOCAB_SIZE] [--base BASE] [--individual_digits INDIVIDUAL_DIGITS] [--consecutive_spaces CONSECUTIVE_SPACES] [--consecutive_tabs CONSECUTIVE_TABS]\n",
    "                          [--consecutive_linebreaks CONSECUTIVE_LINEBREAKS] [--space_behaviour {prefix_all,prefix_sos,split}] [--separate_punctuation SEPARATE_PUNCTUATION] [--enforce_alphabet ENFORCE_ALPHABET] [--output OUTPUT]        \n",
    "                          [--overwrite] [--debug] [--no_verbose]\n",
    "\n",
    "Train a tokenizer.\n",
    "\n",
    "options:\n",
    "  -h, --help            show this help message and exit\n",
    "  --vocab_size VOCAB_SIZE\n",
    "                        Size of output vocabulary (ex: 32000, 65024, ...) (default: 65024)\n",
    "  --base BASE           Base tokenizer (ex: mistralai/Mistral-7B-v0.1) (default: None)\n",
    "  --individual_digits INDIVIDUAL_DIGITS\n",
    "                        Split digits individually (ex: 1999 -> 1┃9┃9┃9) (default: True)\n",
    "  --consecutive_spaces CONSECUTIVE_SPACES\n",
    "                        Maximum number of consecutive spaces (in a same token) (default: 8)\n",
    "  --consecutive_tabs CONSECUTIVE_TABS\n",
    "                        Maximum number of consecutive tabs (in a same token) (default: 4)\n",
    "  --consecutive_linebreaks CONSECUTIVE_LINEBREAKS\n",
    "                        Maximum number of consecutive linebreaks (in a same token) (default: 2)\n",
    "  --space_behaviour {prefix_all,prefix_sos,split}\n",
    "                        How to deal with whitespaces (default: prefix_all)\n",
    "  --separate_punctuation SEPARATE_PUNCTUATION\n",
    "                        Make sure not to mix spaces and punctuations with alphanumeric characters (default: True)\n",
    "  --enforce_alphabet ENFORCE_ALPHABET\n",
    "                        Restrict the alphabet of unicode characters (avoiding 'exotic' characters) (default: True)\n",
    "  --output OUTPUT, -o OUTPUT\n",
    "                        Output folder (will be set automatically if not specified) (default: None)\n",
    "  --overwrite           Overwrite output folder if it already exists (default: False)\n",
    "  --debug               Debug mode (default: False)\n",
    "  --no_verbose\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"surgery\">🤖👩🏻‍⚕️ Tokenizer Surgery</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tokenizer can be modified by\n",
    "* Adding new tokens (sometimes special tokens)\n",
    "* Removing some tokens (very seldom...)\n",
    "* Changing some options (padding side)\n",
    "* Adding new templates\n",
    "\n",
    "Doing this can be a mess, more than expected...\n",
    "It turns out than modifying JSON files (programmatically) is rather a good way to do all this..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
